EvAppObj$Quit()
}
rm(list=ls())
library(dplyr)
library(geosphere)
library(sp)
library(rgdal)
library(raster)
library(adehabitatHR)
library(plotKML)
export.path = 'C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/2020-07-11/Exports/'
dir.create(export.path)
# Get a list of .EV files in your data directory
evFiles = dir(evfile.path,full.names=T,pattern='.EV$')
# Create Functions: call files to determine calibration list - using string to determine vessel calibration
right = function (string, char){substr(string,nchar(string)-(char-1),nchar(string))}
left = function (string,char){substr(string,1,char)}
#substrRight <- function(x, n){  substr(x, nchar(x)-n+1, nchar(x))}
# Setting up calibrations
# Need to change the first number according to the pathway
# Isolate the vessel two letters (i.e. LM)
cal_file_search <- NULL
for(i in 1:length(evFiles)){
cal_file_search [i] <- right(left(evFiles[i],70),2)
}
cal_file_search
calFiles = dir(calfile.path,full.names=T,pattern='.ecs$')
calFiles <- grep("Cal_2020.e", calFiles, value =TRUE, fixed =TRUE) #really odd R bug, had to code it this way.
ordered_calFiles <- NULL
for(i in 1:length(calFiles)){
ordered_calFiles[i] <- grep(cal_file_search[i], calFiles, value = TRUE, fixed = TRUE)
}
ordered_calFiles
#check if they match
evFiles
rawFiles = dir(data.path, full.names=TRUE, pattern='.raw$')
hacFiles = dir(data.path, full.names=TRUE, pattern='.HAC$')
rawFiles <- c(rawFiles,hacFiles)
# Need to code this for time that there is more than one Raw File.
# edit the larger number, looking to isolate the first 4 characters, vessel name_ and first letter of the month. This is to account for the face that there can be multiple data files for one EV.
Files_Search<-NULL
for(i in 1:length(rawFiles)){
Files_Search[i] <- right(left(rawFiles[i],77),4)
}
Files_Search #check to see if there are doubles
Files_Search <- unique(Files_Search) #eliminate the duplicates
rawFileslist<-list()
for(i in 1:length(evFiles)){
rawFileslist[[i]] <- grep(Files_Search[i], rawFiles, value = TRUE, fixed = TRUE)
}
# HAC files does not have a cal, use this script to point to   NULL CAL
# if there are no HAC files:
ordered_calFiles <- c(ordered_calFiles, rep("", length(hacFiles)))
lengthRawFiles <-(length(rawFiles) - length(hacFiles))
lengthHacFiles <- length(rawFiles)
#for hac files go from lengthRawFiles+1:lengthHacFiles
if(lengthHacFiles == lengthRawFiles){
lengthHacFiles <- 0
}
lengthHacFiles
# Export Region Logs (Transects)
for(i in 1:length(rawFileslist)){
# Open Echoview COM connection
EvAppObj = COMCreate('EchoviewCom.EvApplication')
#open template for export
EVFile <- EvAppObj$OpenFile(evFiles[i])
#EVFile <- EvAppObj$OpenFile(evFiles[1])
EVFile <- EvAppObj$OpenFile(evFiles[i])
#EVFile <- EvAppObj$OpenFile(evFiles[1])
#Export Regions
EVRegionClass <- EVFile[["RegionClasses"]]
EVTransect<-EVRegionClass$FindByName("Transect")
EVTransect$ExportDefinitions(paste0(transect.path,cal_file_search[i],'.EVR'))
#EVTransect$ExportDefinitions(paste0(transect.path,cal_file_search[1],'.EVR'))
EvAppObj$Quit()
}
#Export Region Logs
for(i in 1:length(rawFileslist)){
# Open Echoview COM connection
EvAppObj = COMCreate('EchoviewCom.EvApplication')
#open template for export
EVFile <- EvAppObj$OpenFile(evFiles[i])
#Export Regions
EVRegionClass <- EVFile[["RegionClasses"]]
EVTransect<-EVRegionClass$FindByName("Unclassified regions")
EVTransect$ExportDefinitions(paste0(region.path,cal_file_search[i],'.EVR'))
EvAppObj$Quit()
}
transectFiles = dir(transect.path,full.names=T,pattern='.EVR$')
transectFiles
regionFiles = dir(region.path,full.names=T,pattern='.EVR$')
regionFiles
library(EchoviewR)
#For EV files with RAW files.
for(i in 1:lengthRawFiles){
# Open Echoview COM connection
EvAppObj = COMCreate('EchoviewCom.EvApplication')
#open template for export
EVFile <- EvAppObj$OpenFile(evFiles[i])
# Load existing EV File with regions.
EVClearRawData(EVFile=EVFile,filesetName='Fileset 1')
EVRegionClass <- EVFile[["RegionClasses"]]
EVunclassified <-EVRegionClass$FindByName("Unclassified regions")
EVtransect <-EVRegionClass$FindByName("Transect")
EVDeleteRegionClass(EVFile=EVFile,EVunclassified)
EVDeleteRegionClass(EVFile=EVFile,EVtransect)
# Add raw data to the new file
EVAddRawData(EVFile, 'Fileset1', unlist(rawFileslist[i]))
# Add calibration files
EVAddCalibrationFile(EVFile, 'Fileset1', ordered_calFiles[i])
#Import Regions
#open Files for import
EVFile$Import(transectFiles[i])
EVFile$Import(regionFiles[i])
#perform export integretation on region classes called "Transect" only.
EVVar <- EVFile[["Variables"]]$FindByName("Processed data 1")
if(is.null(EVVar) == TRUE){
EVVar <- EVFile[["Variables"]]$FindByName("Attenuated signal removal 1")
}
if(is.null(EVVar) == TRUE){
EVVar <- EVFile[["Variables"]]$FindByName("Sv raw pings T1")
}
EVminThresholdSet(EVVar, -70)
varAnaly <- EVVar[["Properties"]][["Analysis"]]
varAnaly[["ExcludeAbove"]] <- "Surface"
varAnaly[["ExcludeBelow"]] <- "Bottom"
EVRegionClass <- EVFile[["RegionClasses"]]
EVTransect<-EVRegionClass$FindByName("Transect")
EVVar$ExportIntegrationByRegions(paste0(export.path,cal_file_search[i],'.csv'),EVTransect)
EvAppObj$Quit()
}
home.path = 'C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/'
data.path = 'C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/2020-07-11/Data/'
evfile.path ='C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/2020-07-11/'
calfile.path = 'C:/Users/herri/OneDrive/Documents/Calibrations/2020/'
# These folders will be created within the script
transect.path = 'C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/2020-07-11/Transects/'
region.path = 'C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/2020-07-11/Regions/'
export.path = 'C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/2020-07-11/Exports/'
install.packages("RDCOMClient",repos="http://www.omegahat.net/R")
if (!requireNamespace("devtools",quietly=TRUE)) install.packages("devtools")
devtools::install_github("AustralianAntarcticDivision/EchoviewR", build_opts = c("--no-resave-data", "--no-manual"), force = TRUE)
home.path = 'C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/'
data.path = 'C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/2020-07-11/Data/'
evfile.path ='C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/2020-07-11/'
calfile.path = 'C:/Users/herri/OneDrive/Documents/Calibrations/2020/'
transect.path = 'C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/2020-07-11/Transects/'
region.path = 'C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/2020-07-11/Regions/'
export.path = 'C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/2020-07-11/Exports/'
dir.create(region.path)
dir.create(transect.path)
dir.create(export.path)
evFiles = dir(evfile.path,full.names=T,pattern='.EV$')
# Create Functions: call files to determine calibration list - using string to determine vessel calibration
right = function (string, char){substr(string,nchar(string)-(char-1),nchar(string))}
left = function (string,char){substr(string,1,char)}
#substrRight <- function(x, n){  substr(x, nchar(x)-n+1, nchar(x))}
# Setting up calibrations
# Need to change the first number according to the pathway
# Isolate the vessel two letters (i.e. LM)
cal_file_search <- NULL
for(i in 1:length(evFiles)){
cal_file_search [i] <- right(left(evFiles[i],70),2)
}
cal_file_search
calFiles = dir(calfile.path,full.names=T,pattern='.ecs$')
calFiles <- grep("Cal_2020.e", calFiles, value =TRUE, fixed =TRUE) #really odd R bug, had to code it this way.
ordered_calFiles <- NULL
for(i in 1:length(calFiles)){
ordered_calFiles[i] <- grep(cal_file_search[i], calFiles, value = TRUE, fixed = TRUE)
}
ordered_calFiles
#check if they match
evFiles
rawFiles = dir(data.path, full.names=TRUE, pattern='.raw$')
hacFiles = dir(data.path, full.names=TRUE, pattern='.HAC$')
rawFiles <- c(rawFiles,hacFiles)
# Need to code this for time that there is more than one Raw File.
# edit the larger number, looking to isolate the first 4 characters, vessel name_ and first letter of the month. This is to account for the face that there can be multiple data files for one EV.
Files_Search<-NULL
for(i in 1:length(rawFiles)){
Files_Search[i] <- right(left(rawFiles[i],77),4)
}
Files_Search #check to see if there are doubles
Files_Search <- unique(Files_Search) #eliminate the duplicates
rawFileslist<-list()
for(i in 1:length(evFiles)){
rawFileslist[[i]] <- grep(Files_Search[i], rawFiles, value = TRUE, fixed = TRUE)
}
# HAC files does not have a cal, use this script to point to   NULL CAL
# if there are no HAC files:
ordered_calFiles <- c(ordered_calFiles, rep("", length(hacFiles)))
lengthRawFiles <-(length(rawFiles) - length(hacFiles))
lengthHacFiles <- length(rawFiles)
#for hac files go from lengthRawFiles+1:lengthHacFiles
if(lengthHacFiles == lengthRawFiles){
lengthHacFiles <- 0
}
lengthHacFiles
# Export Region Logs (Transects)
for(i in 1:length(rawFileslist)){
# Open Echoview COM connection
EvAppObj = COMCreate('EchoviewCom.EvApplication')
#open template for export
EVFile <- EvAppObj$OpenFile(evFiles[i])
#EVFile <- EvAppObj$OpenFile(evFiles[1])
EVFile <- EvAppObj$OpenFile(evFiles[i])
#EVFile <- EvAppObj$OpenFile(evFiles[1])
#Export Regions
EVRegionClass <- EVFile[["RegionClasses"]]
EVTransect<-EVRegionClass$FindByName("Transect")
EVTransect$ExportDefinitions(paste0(transect.path,cal_file_search[i],'.EVR'))
#EVTransect$ExportDefinitions(paste0(transect.path,cal_file_search[1],'.EVR'))
EvAppObj$Quit()
}
#Export Region Logs
for(i in 1:length(rawFileslist)){
# Open Echoview COM connection
EvAppObj = COMCreate('EchoviewCom.EvApplication')
#open template for export
EVFile <- EvAppObj$OpenFile(evFiles[i])
#Export Regions
EVRegionClass <- EVFile[["RegionClasses"]]
EVTransect<-EVRegionClass$FindByName("Unclassified regions")
EVTransect$ExportDefinitions(paste0(region.path,cal_file_search[i],'.EVR'))
EvAppObj$Quit()
}
transectFiles = dir(transect.path,full.names=T,pattern='.EVR$')
transectFiles
regionFiles = dir(region.path,full.names=T,pattern='.EVR$')
regionFiles
library(EchoviewR)
#For EV files with RAW files. Meat and Potatoes for Exporting
for(i in 1:lengthRawFiles){
# Open Echoview COM connection
EvAppObj = COMCreate('EchoviewCom.EvApplication')
#open template for export
EVFile <- EvAppObj$OpenFile(evFiles[i])
# Load existing EV File with regions.
EVClearRawData(EVFile=EVFile,filesetName='Fileset 1')
EVRegionClass <- EVFile[["RegionClasses"]]
EVunclassified <-EVRegionClass$FindByName("Unclassified regions")
EVtransect <-EVRegionClass$FindByName("Transect")
EVDeleteRegionClass(EVFile=EVFile,EVunclassified)
EVDeleteRegionClass(EVFile=EVFile,EVtransect)
# Add raw data to the new file
EVAddRawData(EVFile, 'Fileset1', unlist(rawFileslist[i]))
# Add calibration files
EVAddCalibrationFile(EVFile, 'Fileset1', ordered_calFiles[i])
#Import Regions
#open Files for import
EVFile$Import(transectFiles[i])
EVFile$Import(regionFiles[i])
#perform export integretation on region classes called "Transect" only.
EVVar <- EVFile[["Variables"]]$FindByName("Processed data 1")
if(is.null(EVVar) == TRUE){
EVVar <- EVFile[["Variables"]]$FindByName("Attenuated signal removal 1")
}
if(is.null(EVVar) == TRUE){
EVVar <- EVFile[["Variables"]]$FindByName("Sv raw pings T1")
}
EVminThresholdSet(EVVar, -70)
varAnaly <- EVVar[["Properties"]][["Analysis"]]
varAnaly[["ExcludeAbove"]] <- "Surface"
varAnaly[["ExcludeBelow"]] <- "Bottom"
EVRegionClass <- EVFile[["RegionClasses"]]
EVTransect<-EVRegionClass$FindByName("Transect")
EVVar$ExportIntegrationByRegions(paste0(export.path,cal_file_search[i],'.csv'),EVTransect)
EvAppObj$Quit()
}
setwd('C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/2020-07-11/Exports/')
TS38 <- -35.5 ###### Code directly to Length Frequences EVENTUALLY ##########
TS50 <- -35.609 ###### Code directly to Length Frequences EVENTUALLY ##########
file_list <- list.files(path = getwd())
transects <- data.frame()
#identify columns to keep from csv files
keep <- c("Region_name","Lat_S","Lon_S","Lat_E","Lon_E","Dist_S","Dist_E","Area_Backscatter_Strength", "Frequency","Time_S","Time_E")
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
rm(temp_data,temp_data2)
transects
file_list <- list.files(path = getwd())
transects <- data.frame()
head(transects)
file_list <- list.files(path = getwd())
transects <- data.frame()
transects
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
transects
#identify columns to keep from csv files
keep <- c("Region_ID", "Region_name", "Region_class", "Process_ID", "Depth_mean", "Ping_S", "Ping_E", "Date_S", "Time_S", "Date_E","Time_E", "Program_version", "Processing_date", "Processing_time","EV_filname", "Uncorrected_area", "Region_notes","Lat_S","Lon_S","Lat_E","Lon_E","Dist_S","Dist_E","Area_Backscatter_Strength", "Frequency","Time_S","Time_E")
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
#identify columns to keep from csv files
keep <- c("Region_ID", "Region_name", "Region_class", "Process_ID", "Depth_mean", "Ping_S", "Ping_E", "Date_S", "Time_S", "Date_E","Time_E", "Program_version", "Processing_date", "Processing_time","EV_filename", "Uncorrected_area", "Region_notes","Lat_S","Lon_S","Lat_E","Lon_E","Dist_S","Dist_E","Area_Backscatter_Strength", "Frequency","Time_S","Time_E")
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
#identify columns to keep from csv files
keep <- c("Region_ID", "Region_name", "Region_class", "Process_ID", "Depth_mean", "Ping_S", "Ping_E", "Date_S", "Time_S", "Date_E","Time_E", "Program_version", "Processing_date", "Processing_time","EV_filename", "Uncorrected_area", "Region_notes","Lat_S","Lon_S","Lat_E","Lon_E","Dist_S","Dist_E","Area_Backscatter_Strength", "Frequency")
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
#identify columns to keep from csv files
keep <- c("Region_ID", "Region_name", "Region_class", "Process_ID", "Depth_mean", "Ping_S", "Ping_E", "Date_S", "Time_S", "Date_E","Time_E", "Program_version", "Processing_date", "Processing_time","EV_filename", "Uncorrected_area", "Region_notes","Lat_S","Lon_S","Lat_E","Lon_E","Dist_S","Dist_E","Area_Backscatter_Strength", "Frequency")
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
setwd('C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/2020-07-11/Exports/')
TS38 <- -35.5 ###### Code directly to Length Frequences EVENTUALLY ##########
TS50 <- -35.609 ###### Code directly to Length Frequences EVENTUALLY ##########
file_list <- list.files(path = getwd())
transects <- data.frame()
head(transects)
#identify columns to keep from csv files
keep <- c("Region_ID", "Region_name", "Region_class", "Process_ID", "Depth_mean", "Ping_S", "Ping_E", "Date_S", "Time_S", "Date_E","Time_E", "Program_version", "Processing_date", "Processing_time","EV_filename", "Uncorrected_area", "Region_notes","Lat_S","Lon_S","Lat_E","Lon_E","Dist_S","Dist_E","Area_Backscatter_Strength", "Frequency")
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
#identify columns to keep from csv files
keep <- c("Region_ID", "Region_name", "Region_class", "Process_ID", "Depth_mean", "Ping_S", "Ping_E", "Dist_S","Dist_E", "Date_S", "Time_S", "Date_E","Time_E", "Lat_S","Lon_S","Lat_E","Lon_E", "Program_version", "Processing_date", "Processing_time","EV_filename", "Uncorrected_area","Area_Backscatter_Strength", "Frequency",  "Region_notes")
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
#identify columns to keep from csv files
keep <- c("Region_ID", "Region_name", "Region_class", "Process_ID", "Depth_mean", "Ping_S", "Ping_E")
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
#identify columns to keep from csv files
keep <- c("Dist_S","Dist_E", "Date_S", "Time_S", "Date_E","Time_E", "Lat_S","Lon_S","Lat_E","Lon_E")
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
#identify columns to keep from csv files
keep <- c("Dist_S","Dist_E", "Date_S", "Time_S", "Date_E","Time_E", "Lat_S","Lon_S","Lat_E","Lon_E", "Region_ID")
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
#identify columns to keep from csv files
keep <- c("Dist_S","Dist_E", "Date_S", "Time_S", "Date_E","Time_E", "Lat_S","Lon_S","Lat_E","Lon_E", "Region_name")
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
setwd('C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/2020-07-11/Exports/')
TS38 <- -35.5 ###### Code directly to Length Frequences EVENTUALLY ##########
TS50 <- -35.609 ###### Code directly to Length Frequences EVENTUALLY ##########
file_list <- list.files(path = getwd())
transects <- data.frame()
#identify columns to keep from csv files
keep <- c("Dist_S","Dist_E", "Date_S", "Time_S", "Date_E","Time_E", "Lat_S","Lon_S","Lat_E","Lon_E", "Region_name")
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
#identify columns to keep from csv files
keep <- c("Dist_S","Dist_E", "Date_S", "Time_S", "Date_E","Time_E", "Lat_S","Lon_S","Lat_E","Lon_E", "Region_name", "Ping_S", "Ping_E", "EV_filename","Area_Backscatter_Strength", "Frequency)
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
# Use trans function
transects
rm(temp_data,temp_data2)
transects_German <- filter(transects, Lat_S <43.67 & Lat_E < 43.67 & Lon_S < -66.259 & Lon_E < -66.259) #need to check whether this is accurate
transects_SealIsland <-  filter(transects, !Region_name %in% as.character(transects_German$Region_name))
transects_German<- rbind(transects_German, transects_SealIsland[7,])
transects_German
transects_SealIsland<-transects_SealIsland[1:6,]
#### German Bank ####
#calculate area of survey
area_calc = function(x) {
Longitude  <-c(x$Lon_S,x$Lon_E)
Latitude  <-c(x$Lat_S, x$Lat_E)
LatLonMat <-matrix(c(Longitude,Latitude),ncol=2)
survey_coord <-SpatialPoints(LatLonMat)
crs.geo <- CRS("+proj=utm +zone=20 +datum=WGS84")
proj4string(survey_coord) <- crs.geo
is.projected(survey_coord)
summary(survey_coord)
survey_area <- mcp(survey_coord, percent = 100)
area<-survey_area$area*100000000 #Converts to km squared. originally in Hectares, but not sure why it's million too small.
return(area)
}
area<-area_calc(transects_German)
biomassCalc = function(x, area) {
TS38 <- -35.5 ###### Code directly to Length Frequences EVENTUALLY ##########
TS50 <- -35.609 ###### Code directly to Length Frequences EVENTUALLY ##########
#x = transects_German
x$areaKm = area
# Analysis
x$distance = (x$Dist_E - x$Dist_S)/1000
x$sum_trans =sum(x$distance)
x$Actual_Weighting = (x$distance)/(x$sum_trans)
x$calc_actual_mean_sa = 10^(x$Area_Backscatter_Strength/10)*x$Actual_Weighting
x$TS <- as.numeric(ifelse(grepl(38, x$Frequency), TS38, TS50))
x$biomass_density = 10^((x$Area_Backscatter_Strength-(x$TS))/10) # same as Jenna's Transects.R script calculation
x$density = (x$biomass_density)*(x$distance)
x$weighted_mean_biomass_calc = (x$biomass_density) * (x$Actual_Weighting)
x$trans_biomass = (x$weighted_mean_biomass_calc) * x$areaKm * 1000
x$total_biomass = sum(x$trans_biomass)
se <- function(x) sqrt(var(x)/length(x))
x$se = se(x$biomass_density)
x$standard_error_tonnes = x$se * x$areaKm * 1000
x$standard_error_perc = x$standard_error_tonnes/x$total_biomass*100
x$mean_biomass_density = mean(x$biomass_density)
x$meanSa = 10*log10(sum(x$calc_actual_mean_sa))
return(x)
}
transects_German
biomassCalc(transects_German,area)
#Seal Island
area<-area_calc(transects_SealIsland)
area
biomassCalc(transects_SealIsland,area)
#identify columns to keep from csv files
keep <- c("Dist_S","Dist_E", "Date_S", "Time_S", "Date_E","Time_E", "Lat_S","Lon_S","Lat_E","Lon_E", "Region_name", "Ping_S", "Ping_E", "EV_filename","Area_Backscatter_Strength", "Frequency")
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
setwd('C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/2020-07-11/Exports/')
TS38 <- -35.5 ###### Code directly to Length Frequences EVENTUALLY ##########
TS50 <- -35.609 ###### Code directly to Length Frequences EVENTUALLY ##########
file_list <- list.files(path = getwd())
transects <- data.frame()
#identify columns to keep from csv files
keep <- c("Dist_S","Dist_E", "Date_S", "Time_S", "Date_E","Time_E", "Lat_S","Lon_S","Lat_E","Lon_E", "Region_name", "Ping_S", "Ping_E", "EV_filename","Area_Backscatter_Strength", "Frequency")
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
transects
transects(transects, TS38 = -35.5, TS50 = -35.609)
loadfunctions( "acousticHerring")
getwd()
libPaths()
setwd("C:","Users", "herri","OneDrive", "Documents", "Jenna", "ecomod_data")
setwd('C:/Users/herri/OneDrive/Documents/Jenna/ecomod_data')
loadfunctions( "acousticHerring")
setwd('C:/Users/herri/OneDrive/Documents/Jenna/ecomod_data/acousticHerring/src/_Rfunctions/')
setwd('C:/Users/herri/OneDrive/Documents/Jenna/ecomod_data/acousticHerring/src/_Rfunctions/')
setwd('C:/Users/herri/OneDrive/Documents/Jenna/ecomod/acousticHerring/src/_Rfunctions/')
source(transects)
getwd()
source("transects.R")
setwd('C:/Users/herri/OneDrive/Documents/Surveys/2020/Scots Bay/2020-07-11/Exports/')
file_list <- list.files(path = getwd())
transects <- data.frame()
#identify columns to keep from csv files
keep <- c("Dist_S","Dist_E", "Date_S", "Time_S", "Date_E","Time_E", "Lat_S","Lon_S","Lat_E","Lon_E", "Region_name", "Ping_S", "Ping_E", "EV_filename","Area_Backscatter_Strength", "Frequency")
#for each file in file_list, read in csv, keep specified columns, rbind to dataset to produce one dataset
for (i in 1:length(file_list)){
temp_data <- read.csv(file_list[i])
temp_data2 <- temp_data[keep]
transects <- rbind(transects, temp_data2)
}
transects(transects, TS38 = -35.5, TS50 = -35.609)
# Use trans function
setwd('C:/Users/herri/OneDrive/Documents/Jenna/ecomod/acousticHerring/src/_Rfunctions/')
source("transects.R")
transects(transects, TS38 = -35.5, TS50 = -35.609)
source("transects.R")
transects(transects, TS38 = -35.5, TS50 = -35.609)
