i= "7. This is a non-fishing survey."
h=if(Allocation == 0){
print(i)
}
f=if(surv=="SB" & Allocation != 0){
paste0("7. Fishing to start on ", c, ", and allocation is ", d)
}
g=if(surv=="GB" & Allocation != 0){
paste0("7. Fishing to start on ", c, ", and allocation is ", e)
}
if(surv=="SB"){
cat("\n")
cat("### Tidal Charts", "\n")
cat("\n")
knitr::include_graphics(path=paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", surv, surv.no, "/Hourly.jpg"), rel_path = FALSE)
}
if(surv=="SB"){
knitr::include_graphics(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", surv, surv.no, "/Daily.jpg"), rel_path = FALSE)
}
#save all changes and information to a .csv for Update Data and results
CurrentData = tibble(FlowmeterType = "General Oceanics", TowType = "Surface Tow", Gear = "1/500", PlanktonVessel = PlanktonVessel, EVessel = EVessel, NVessel = NVessel, Survey.No = surv.no, Ground = surv, Vessel.No = vessels, Net = "1")
Month = substr(StartDate, 6,7)
Day = substr(StartDate, 9,10)
Year = substr(StartDate, 1,4)
CurrentData$Date = as.character(paste0(Day,"/",Month,"/",Year))
CurrentData$StartTime = as.character(StartTime)
CurrentData = CurrentData %>%
mutate(ExtraBox = ifelse(!is.na(EVessel) & is.na(NVessel), "East",
ifelse(is.na(EVessel) & !is.na(NVessel), "North",
ifelse(!is.na(EVessel) & !is.na(NVessel), "Both",
ifelse(is.na(EVessel) & is.na(NVessel), "None",
NA))))) %>%
mutate(Fishing = ifelse(Allocation > 0 | !is.na(Allocation), "Y", "N")) %>%
mutate(PlanktonVessel = ifelse(PlanktonVessel == "Lady Janice", "Lady Janice II", PlanktonVessel))
CurrentData %>% write_csv((paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", surv, surv.no, "/Plan Data.csv")))
## Global options
rm(list = ls()) #removes everything in the current environment
#Change these options
surv = "SB"
surv2 = "Scots Bay"
surv.date = "2025-MM-DD XX:XX:XX" #survey date and time, as formatted
surv.no = "99"
Allocation = "X" #set to "0" for a non-fishing survey
SIAllocation = "0" #Seal Island allocation for GB-only
Tagging = NA #list vessel names in a single quote string (e.g. "Lady Melissa and Sealife II")
#Set vessels below
vessels = 3
EVessel = NA #Set NA for GB or excluding box
NVessel = NA #Set NA for GB or excluding box
PlanktonVessel = NA
#Main box only (e.g. if vessels = 9 with both SB boxes, should have 1 Evessel, 1 Nvessel, and 7 Vessels below)
V1 = "V1"
V2 = "V2"
V3 = "V3"
V4 = NA
V5 = NA
V6 = NA
V7 = NA
V8 = NA
V9 = NA
knitr::opts_knit$set(root.dir = paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/")) #sets the root directory for the entire document, when it isnt changed elsewhere by setwd()
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, fig.align='center') #sets the coding chunk options of the whole document to not appear in the actual document (echo)
#Import all packages and data
library(ggplot2)
library(patchwork)
library(scales)
library(cli)
library(lubridate)
library(reprex)
library(tidyverse)
library(geosphere)
library(reshape2)
library(moderndive)
library(skimr)
library(ggridges)
#library(weathercan)
library(GGally)
library(psych)
library(raster)
library(PBSmapping)
library(rgeos) #this is an old version, and downloaded from archieve.
library(sf)
library(terra)
library(knitr)
library(kableExtra)
library(grid)
library(gridExtra)
library(cowplot)
library(DT)
library(dygraphs)
library(leaflet)
library(rmapshaper)
library(plotly)
library(mapproj)
library(oce) #new CTD Data package
library(pander)
library(geodata) #this is an old version, and downloaded from archive.
library(pacman)
library(rnaturalearth)
library(rnaturalearthdata)
library(raster)
library(devtools)
library(maps)
library(dplyr)
source("/Users/herri/Herring Science Council/Science Team - Documents/R Functions/getData.R")
#Parse date time
surv.date = as.POSIXlt(surv.date, format="%Y-%m-%d %H:%M:%S")
StartTime = substr(surv.date, 12,19) #turns the 12th-19th section of surv.date into the start time (the 20:00:00 time of surv.date)
StartDate = substr(surv.date, 1,10) #turns the 1st-10th section of surv.date into the start date (the 2023-01-01 date of surv.date)
year = substr(surv.date, 1,4)
#Create Plan by combining main box with any extra boxes
# Plan = read_csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", surv, surv.no, "/survey plan.csv"))
#above line is only used if a manual plan override is needed, the ignore the below code (can '#' it to temporarily disable it)
vessels2 = ifelse(is.na(EVessel) & is.na(NVessel), vessels, #if no east + north vessels (SB), total number of main box vessels is equal to 'vessels' without changes
ifelse(!is.na(EVessel) & is.na(NVessel), vessels-1, #if there is an east vessel (but not north), total # of main box vessels is equal to 'vessels' minus 1
ifelse(is.na(EVessel) & !is.na(NVessel), vessels-1, #if there is a north vessel (but not east), total # of main box vessels is equal to 'vessels' minus 1
ifelse(!is.na(EVessel) & !is.na(NVessel), vessels-2, #if there is both an east + north vessel, total number of main box vessels is equal to 'vessels' minus 2
NA))))
Main = read_csv(paste0("C:/Users/", Sys.info()[7], "/Documents/GitHub/HerringScience.github.io/Surveys/Survey Lines/", surv, "/V", vessels2, ".csv"))
#the above line loads the default V# spreadsheets with the proper box spacing, based on number of attending vessels.
if(!is.na(NVessel)){North = read_csv(paste0("C:/Users/", Sys.info()[7], "/Documents/GitHub/HerringScience.github.io/Surveys/Survey Lines/", surv, "/North_Box.csv"))}
#if there is a NVessel this will load the North_Box.csv box outline
if(!is.na(EVessel)){East = read_csv(paste0("C:/Users/", Sys.info()[7], "/Documents/GitHub/HerringScience.github.io/Surveys/Survey Lines/", surv, "/East_Box.csv"))}
#if there is a EVessel this will load the East_Box.csv box outline
if(!is.na(NVessel) & is.na(EVessel)){Plan = full_join(Main, North)} #if there is a north vessel (but not east), the plan combines (full join) the main box + north box
if(is.na(NVessel) & !is.na(EVessel)){Plan = full_join(Main, East)} #if there is an east vessel (but not north), the plan combines (full join) the main box + east box
if(!is.na(NVessel) & !is.na(EVessel)){
Plan = full_join(Main, North)
Plan = full_join(Plan, East)} #if there is both an east and north vessel, the plan combines main + north first, then this combined frame with + east box.
if(is.na(NVessel) & is.na(EVessel)){Plan = Main} #if there is only main box vessels, the plan is equal to the main box plan with no changes.
#Add vessel names to Plan
Plan = Plan %>% #renames the base "V#" Vessels in the plan to the actual vessel names manually listed in the first code chunk.
mutate(Vessel = replace(Vessel, Vessel == "V1", V1)) %>%
mutate(Vessel = replace(Vessel, Vessel == "V2", V2)) %>%
mutate(Vessel = replace(Vessel, Vessel == "V3", V3)) %>%
mutate(Vessel = replace(Vessel, Vessel == "V4", V4)) %>%
mutate(Vessel = replace(Vessel, Vessel == "V5", V5)) %>%
mutate(Vessel = replace(Vessel, Vessel == "V6", V6)) %>%
mutate(Vessel = replace(Vessel, Vessel == "V7", V7)) %>%
mutate(Vessel = replace(Vessel, Vessel == "V8", V8)) %>%
mutate(Vessel = replace(Vessel, Vessel == "V9", V9)) %>%
mutate(Vessel = replace(Vessel, Vessel == "NVessel", NVessel)) %>%
mutate(Vessel = replace(Vessel, Vessel == "EVessel", EVessel))
#Short-hand names and save for Update Data script usage
Plan2 = Plan %>% #convert the vessel names (on a separate Plan2) to their shorthand forms for other tools to use
mutate(Vessel = replace(Vessel, Vessel == "Leroy and Barry", "LB")) %>%
mutate(Vessel = replace(Vessel, Vessel == "Morning Star", "MS")) %>%
mutate(Vessel = replace(Vessel, Vessel == "Canada 100", "C1")) %>%
mutate(Vessel = replace(Vessel, Vessel == "Fundy Monarch", "FM")) %>%
mutate(Vessel = replace(Vessel, Vessel == "Brunswick Provider", "BP")) %>%
mutate(Vessel = replace(Vessel, Vessel == "Lady Melissa", "LM")) %>%
mutate(Vessel = replace(Vessel, Vessel == "Sealife II" | Vessel == "Sealife", "SL")) %>%
mutate(Vessel = replace(Vessel, Vessel == "Lady Janice" | Vessel == "Lady Janice II", "LJ")) %>%
mutate(Vessel = replace(Vessel, Vessel == "Tasha Marie", "TM"))
write_csv(x=Plan2, file=paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", surv, surv.no, "/survey plan.csv"))
#Comment out to here for manual plans.
#Land Data
#can<-getData('GADM', country="CAN", level=1) #getData is discontinued
can<-gadm(country='CAN', level=1, path = "geodata_default_path",version="latest", resolution = 1, regions = c("New Brunswick", "Nova Scotia", "Prince Edward Island", "Newfoundland and Labrador", "Québec"))
#us = getData('GADM', country = "USA", level = 1) # getData is discontinued
us<-gadm(country='USA', level=1, path = "geodata_default_path",version="latest", resolution = 1, regions = c("Maine"))
can1 = rbind(can,us)
NBNS = can1
# NBNS <- can1[can1@data$NAME_1%in%c("New Brunswick","Nova Scotia","Prince Edward Island","Newfoundland and Labrador","Québec", "Maine"),]
NBNS <- as(NBNS, "Spatial") #This causes it to run very slowly - takes a few minutes to process.
# Proper coordinates for German Bank
GBMap <- as(extent(-66.5, -65.5, 43, 44), "SpatialPolygons")
proj4string(GBMap) <- CRS(proj4string(NBNS))
rm(list = ls())
#Change these options
surv = "SB"
surv2 = "Scots Bay"
year = "2025"
surv.no = "1"
hightide = "2025-05-06 20:32:00" #for Scots Bay only
## Global options
knitr::opts_knit$set(root.dir = paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/"))
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE)
#Import all packages, CTD data, and land data
#Packages
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Main Data"))
library(rlang)
library(cli)
library(lubridate)
library(reprex)
library(tidyverse)
library(geosphere)
library(reshape2)
library(moderndive)
library(skimr)
library(ggridges)
#library(weathercan)
library(GGally)
library(psych)
library(raster)
library(PBSmapping)
#library(rgeos)
library(knitr)
library(kableExtra)
library(grid)
library(gridExtra)
library(cowplot)
library(readxl)
library(hms)
library(measurements)
library(ggplot2)
library(patchwork)
library(scales)
library(sf)
library(terra)
library(DT)
library(dygraphs)
library(leaflet)
library(rmapshaper)
library(plotly)
library(mapproj)
library(oce) #new CTD Data package
library(pander)
library(geodata) #this is an old version, and downloaded from archive.
library(pacman)
library(rnaturalearth)
library(rnaturalearthdata)
library(raster)
library(devtools)
library(maps)
library(dplyr)
#Survey Data
Survey = read_csv("Survey Data.csv") #Survey Data
Survey$Year = as.factor(Survey$Year)
Survey$Ground = as.factor(Survey$Ground)
#Tagging Data
Tag = read_csv("TaggingEvents.csv") #Tagging Data
polysT = read_csv("timGrounds.csv") #Coloured ground maps
Tag$Year = as.factor(Tag$Year)
Tag$Vessel = as.factor(Tag$Vessel)
Tag$Survey = as.factor(Tag$Survey)
Tag$Tagger = as.factor(Tag$Tagger)
#CTD Data
SST = read_csv("CTD SST.csv") #SST
polysT = read_csv("timGrounds.csv") #coloured ground maps
CTD = read_csv("CTD Full.csv") #All Data
atDepth = read_csv("CTD 30m.csv") #At 30m Depth > This one contains all Stratified Temp + Salinity data as well
SST$Year <- as.factor(SST$Year)
SST$Month <- as.factor(SST$Month)
atDepth$Year <- as.factor(atDepth$Year)
atDepth$Month <- as.factor(atDepth$Month)
CTD$Year <- as.factor(CTD$Year)
CTD$Month <- as.factor(CTD$Month)
CTD$Survey <- as.factor(CTD$Survey)
CTD <- CTD %>%
mutate(Julian_factor = Julian)
CTD$Julian_factor <- as.factor(CTD$Julian_factor)
CTD2=CTD
#SSB Data
SSB = read_csv("SSB Estimates.csv")
SSB$Year <- as.factor(SSB$Year)
SSB$Survey_Number <- as.factor(SSB$Survey_Number)
SSB$Ground <- as.factor(SSB$Ground)
#Larval Data
Larval = read_csv("Full Larval.csv")
Larval$Year <- as.factor(Larval$Year)
Larval$category <- as.factor(Larval$category)
Larval$Survey.No <- as.factor(Larval$Survey.No)
#Land Data
#can<-getData('GADM', country="CAN", level=1) #getData is discontinued
can<-gadm(country='CAN', level=1, path = "geodata_default_path",version="latest", resolution = 1, regions = c("New Brunswick", "Nova Scotia", "Prince Edward Island", "Newfoundland and Labrador", "Québec"))
#us = getData('GADM', country = "USA", level = 1) # getData is discontinued
us<-gadm(country='USA', level=1, path = "geodata_default_path",version="latest", resolution = 1, regions = c("Maine"))
can1 = rbind(can,us)
NBNS = can1
# NBNS <- can1[can1@data$NAME_1%in%c("New Brunswick","Nova Scotia","Prince Edward Island","Newfoundland and Labrador","Québec", "Maine"),]
NBNS <- as(NBNS, "Spatial") #This causes it to run very slowly - takes a few minutes to process.
# Proper coordinates for German Bank
GBMap <- as(extent(-66.5, -65.5, 43, 44), "SpatialPolygons")
proj4string(GBMap) <- CRS(proj4string(NBNS))
GBout <- crop(NBNS, GBMap, byid=TRUE)
# Proper coordinates for Scots Bay
SBMap <- as(extent(-65.5, -64.5, 45, 45.5), "SpatialPolygons")
proj4string(SBMap) <- CRS(proj4string(NBNS))
SBout <- crop(NBNS, SBMap, byid=TRUE)
#Import All Boxes
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Box Coordinates/"))
boxes = read.csv("surveyBoxes.csv")
# Scots Bay plankton and CTD box
SBplankton=boxes[which(boxes$Box == "SBPlanktonBox"), ]
SBCTD=boxes[which(boxes$Box == "SBocean"), ]
#German Bank CTD box
GBCTD=boxes[which(boxes$Box == "GBocean"), ]
# German Bank
SUA = read.csv("polygon_GB.csv")
polyGB = as.PolySet(SUA, projection="LL")
# Seal Island
SUA = read.csv("polygon_SI.csv")
polySI = as.PolySet(SUA, projection="LL")
Survey = Survey %>% filter(Ground == surv & Survey.No == surv.no & Year == year)
Tag = Tag %>% filter(Ground == surv2 & Survey == surv.no & Year == year)
CTD = CTD %>% filter(Ground == surv2 & Survey == surv.no & Year == year)
current=paste0(unique(Survey$Ground), unique(Survey$Survey.No))
if(surv == "SB"){
if(!is.na(unique(Survey$EVessel))){
SUA = read.csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current, "/polygon_SBEastern.csv"))
polyEastern = as.PolySet(SUA, projection="LL")}
if(!is.na(unique(Survey$NVessel))){
SUA = read.csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current, "/polygon_SBNorthern.csv"))
polyNorthern = as.PolySet(SUA, projection="LL")}
SUA = read.csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current, "/polygon_SB.csv"))
polySB_main = as.PolySet(SUA, projection="LL")}
if(surv == "GB"){
SUA = read.csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current, "/polygon_GB.csv"))
polyGB = as.PolySet(SUA, projection="LL")
SUA = read.csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current, "/polygon_SI.csv"))
polySI = as.PolySet(SUA, projection="LL")
}
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current))
#setwd("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Surveys/ 2024/SB11")
Map = list.files(pattern = "Map*") %>%
map_df(~read_csv(.))
Region = list.files(pattern = "Region*") %>%
map_df(~read_csv(.))
Speed=read_csv("Speed.csv")
rm(list = ls())
#Change these options
surv = "SB"
surv2 = "Scots Bay"
year = "2025"
surv.no = "1"
hightide = "2025-05-06 20:32:00" #for Scots Bay only
## Global options
knitr::opts_knit$set(root.dir = paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/"))
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE)
#Import all packages, CTD data, and land data
#Packages
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Main Data"))
library(rlang)
library(cli)
library(lubridate)
library(reprex)
library(tidyverse)
library(geosphere)
library(reshape2)
library(moderndive)
library(skimr)
library(ggridges)
#library(weathercan)
library(GGally)
library(psych)
library(raster)
library(PBSmapping)
#library(rgeos)
library(knitr)
library(kableExtra)
library(grid)
library(gridExtra)
library(cowplot)
library(readxl)
library(hms)
library(measurements)
library(ggplot2)
library(patchwork)
library(scales)
library(sf)
library(terra)
library(DT)
library(dygraphs)
library(leaflet)
library(rmapshaper)
library(plotly)
library(mapproj)
library(oce) #new CTD Data package
library(pander)
library(geodata) #this is an old version, and downloaded from archive.
library(pacman)
library(rnaturalearth)
library(rnaturalearthdata)
library(raster)
library(devtools)
library(maps)
library(dplyr)
#Survey Data
Survey = read_csv("Survey Data.csv") #Survey Data
Survey$Year = as.factor(Survey$Year)
Survey$Ground = as.factor(Survey$Ground)
#Tagging Data
Tag = read_csv("TaggingEvents.csv") #Tagging Data
polysT = read_csv("timGrounds.csv") #Coloured ground maps
Tag$Year = as.factor(Tag$Year)
Tag$Vessel = as.factor(Tag$Vessel)
Tag$Survey = as.factor(Tag$Survey)
Tag$Tagger = as.factor(Tag$Tagger)
#CTD Data
SST = read_csv("CTD SST.csv") #SST
polysT = read_csv("timGrounds.csv") #coloured ground maps
CTD = read_csv("CTD Full.csv") #All Data
atDepth = read_csv("CTD 30m.csv") #At 30m Depth > This one contains all Stratified Temp + Salinity data as well
SST$Year <- as.factor(SST$Year)
SST$Month <- as.factor(SST$Month)
atDepth$Year <- as.factor(atDepth$Year)
atDepth$Month <- as.factor(atDepth$Month)
CTD$Year <- as.factor(CTD$Year)
CTD$Month <- as.factor(CTD$Month)
CTD$Survey <- as.factor(CTD$Survey)
CTD <- CTD %>%
mutate(Julian_factor = Julian)
CTD$Julian_factor <- as.factor(CTD$Julian_factor)
CTD2=CTD
#SSB Data
SSB = read_csv("SSB Estimates.csv")
SSB$Year <- as.factor(SSB$Year)
SSB$Survey_Number <- as.factor(SSB$Survey_Number)
SSB$Ground <- as.factor(SSB$Ground)
#Larval Data
Larval = read_csv("Full Larval.csv")
Larval$Year <- as.factor(Larval$Year)
Larval$category <- as.factor(Larval$category)
Larval$Survey.No <- as.factor(Larval$Survey.No)
#Land Data
#can<-getData('GADM', country="CAN", level=1) #getData is discontinued
can<-gadm(country='CAN', level=1, path = "geodata_default_path",version="latest", resolution = 1, regions = c("New Brunswick", "Nova Scotia", "Prince Edward Island", "Newfoundland and Labrador", "Québec"))
#us = getData('GADM', country = "USA", level = 1) # getData is discontinued
us<-gadm(country='USA', level=1, path = "geodata_default_path",version="latest", resolution = 1, regions = c("Maine"))
can1 = rbind(can,us)
NBNS = can1
# NBNS <- can1[can1@data$NAME_1%in%c("New Brunswick","Nova Scotia","Prince Edward Island","Newfoundland and Labrador","Québec", "Maine"),]
NBNS <- as(NBNS, "Spatial") #This causes it to run very slowly - takes a few minutes to process.
# Proper coordinates for German Bank
GBMap <- as(extent(-66.5, -65.5, 43, 44), "SpatialPolygons")
proj4string(GBMap) <- CRS(proj4string(NBNS))
GBout <- crop(NBNS, GBMap, byid=TRUE)
# Proper coordinates for Scots Bay
SBMap <- as(extent(-65.5, -64.5, 45, 45.5), "SpatialPolygons")
proj4string(SBMap) <- CRS(proj4string(NBNS))
SBout <- crop(NBNS, SBMap, byid=TRUE)
#Import All Boxes
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Box Coordinates/"))
boxes = read.csv("surveyBoxes.csv")
# Scots Bay plankton and CTD box
SBplankton=boxes[which(boxes$Box == "SBPlanktonBox"), ]
SBCTD=boxes[which(boxes$Box == "SBocean"), ]
#German Bank CTD box
GBCTD=boxes[which(boxes$Box == "GBocean"), ]
# German Bank
SUA = read.csv("polygon_GB.csv")
polyGB = as.PolySet(SUA, projection="LL")
# Seal Island
SUA = read.csv("polygon_SI.csv")
polySI = as.PolySet(SUA, projection="LL")
Survey = Survey %>% filter(Ground == surv & Survey.No == surv.no & Year == year)
Tag = Tag %>% filter(Ground == surv2 & Survey == surv.no & Year == year)
CTD = CTD %>% filter(Ground == surv2 & Survey == surv.no & Year == year)
current=paste0(unique(Survey$Ground), unique(Survey$Survey.No))
if(surv == "SB"){
if(!is.na(unique(Survey$EVessel))){
SUA = read.csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current, "/polygon_SBEastern.csv"))
polyEastern = as.PolySet(SUA, projection="LL")}
if(!is.na(unique(Survey$NVessel))){
SUA = read.csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current, "/polygon_SBNorthern.csv"))
polyNorthern = as.PolySet(SUA, projection="LL")}
SUA = read.csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current, "/polygon_SB.csv"))
polySB_main = as.PolySet(SUA, projection="LL")}
if(surv == "GB"){
SUA = read.csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current, "/polygon_GB.csv"))
polyGB = as.PolySet(SUA, projection="LL")
SUA = read.csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current, "/polygon_SI.csv"))
polySI = as.PolySet(SUA, projection="LL")
}
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current))
#setwd("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Surveys/ 2024/SB11")
Map = list.files(pattern = "Map*") %>%
map_df(~read_csv(.))
Region = list.files(pattern = "Region*") %>%
map_df(~read_csv(.))
Speed=read_csv("Speed.csv")
getwd()
#setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current))
setwd("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Surveys/2025/SB1")
getwd()
list.files()
Map = list.files(pattern = "Map*") %>%
map_df(~read_csv(.))
#setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current))
setwd("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Surveys/2025/SB1")
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current))
Map = list.files(pattern = "Map*") %>%
map_df(~read_csv(.))
Survey = Survey %>% filter(Ground == surv & Survey.No == surv.no & Year == year)
Tag = Tag %>% filter(Ground == surv2 & Survey == surv.no & Year == year)
CTD = CTD %>% filter(Ground == surv2 & Survey == surv.no & Year == year)
current=paste0(unique(Survey$Ground), unique(Survey$Survey.No))
??paste0
#current=paste0(unique(Survey$Ground), unique(Survey$Survey.No))
current = "SB1"
if(surv == "SB"){
if(!is.na(unique(Survey$EVessel))){
SUA = read.csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current, "/polygon_SBEastern.csv"))
polyEastern = as.PolySet(SUA, projection="LL")}
if(!is.na(unique(Survey$NVessel))){
SUA = read.csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current, "/polygon_SBNorthern.csv"))
polyNorthern = as.PolySet(SUA, projection="LL")}
SUA = read.csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current, "/polygon_SB.csv"))
polySB_main = as.PolySet(SUA, projection="LL")}
if(surv == "GB"){
SUA = read.csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current, "/polygon_GB.csv"))
polyGB = as.PolySet(SUA, projection="LL")
SUA = read.csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current, "/polygon_SI.csv"))
polySI = as.PolySet(SUA, projection="LL")
}
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current))
Map = list.files(pattern = "Map*") %>%
map_df(~read_csv(.))
setwd(("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current))
setwd(past0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", current))
getwd()
