library(geosphere)
library(reshape2)
library(moderndive)
library(skimr)
library(ggridges)
#library(weathercan)
library(GGally)
library(psych)
library(raster)
library(PBSmapping)
#library(rgeos)
library(sf)
library(terra)
library(knitr)
library(kableExtra)
library(grid)
library(gridExtra)
library(cowplot)
library(DT)
library(dygraphs)
library(leaflet)
library(rmapshaper)
library(plotly)
library(mapproj)
library(oce) #new CTD Data package
library(pander)
library(geodata)
library(pacman)
library(rnaturalearth)
library(rnaturalearthdata)
library(raster)
library(devtools)
library(maps)
library(dplyr)
devtools::install_github("ropensci/rnaturalearthhires")
install.packages('GADMTools')
install.packages("Rtools44")
state_prov <- rnaturalearth::ne_states(c("united states of america", "canada"))
#Survey Data
surveyData <- read_csv("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Main Data/Survey Data.csv")
#Tagging Data
Tag = read_csv("TaggingEvents.csv") #Tagging Data
polysT = read_csv("timGrounds.csv") #Coloured ground maps
Tag$Year = as.factor(Tag$Year)
Tag$Vessel = as.factor(Tag$Vessel)
Tag$Survey = as.factor(Tag$Survey)
Tag$Tagger = as.factor(Tag$Tagger)
#CTD Data
SST = read_csv("CTD SST.csv") #SST
polysT = read_csv("timGrounds.csv") #coloured ground maps
CTD = read_csv("CTD Full.csv") #All Data
atDepth = read_csv("CTD 30m.csv") #At 30m Depth > This one contains all Stratified Temp + Salinity data as well
SST$Year <- as.factor(SST$Year)
SST$Month <- as.factor(SST$Month)
atDepth$Year <- as.factor(atDepth$Year)
atDepth$Month <- as.factor(atDepth$Month)
CTD$Year <- as.factor(CTD$Year)
CTD$Month <- as.factor(CTD$Month)
CTD$Survey <- as.factor(CTD$Survey)
CTD <- CTD %>%
mutate(Julian_factor = Julian)
CTD$Julian_factor <- as.factor(CTD$Julian_factor)
#SSB Data
SSB = read_csv("SSB Estimates.csv")
SSB$Year <- as.factor(SSB$Year)
SSB$Survey_Number <- as.factor(SSB$Survey_Number)
SSB$Ground <- as.factor(SSB$Ground)
#LRP Data
LRP2 = read_csv("LRP Data.csv")
LRP2 = LRP2 %>% rename(ThreeYear = "3yr Avg")
#Fat Data
FatData = read_csv("Total Fat Data.csv")
#Larval Data
#All Adjusted Ages and Dates are originally added in Larval QC script.
#All preservative length adjustments added in in Larval QC script.
#Changed code within compendium from Lengthmm to LengthAdjustment
Larval = read_csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Main Data/Full Larval Jan 2025.csv"))
LarvalSum = read_csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Main Data/LarvalSum Jan 2025.csv"))
LarvalSum$Year <- as.factor(LarvalSum$Year)
Larval$Date <- lubridate::ymd(Larval$Date)
Larval <- dplyr::arrange(Larval, Date)
Larval$Year <- as.factor(Larval$Year)
Larval$category <- as.factor(Larval$category)
Larval$Survey.No <- as.factor(Larval$Survey.No)
Larval$MonthDay <- format(Larval$Date, "%m-%d")
#Fix this
#Larval$AdjustedJulianSpawnDate <- as.numeric(Larval$AdjustedJulianSpawnDate) #AdjustedJulianSpawnDate is the median of the min and the max spawn date provided.
#Changed to X and Y to fit in better with compendium code. These are the tow start and finish coordinates.
names(Larval)[names(Larval) =="Lon1"] <- "X"
names(Larval)[names(Larval) =="Lat1"] <- "Y"
names(Larval)[names(Larval) =="Lon2"] <- "Xend"
names(Larval)[names(Larval) =="Lat2"] <- "Yend"
#Seal Island Larval
LarvalSI = filter(Larval, Ground == "SI")
LarvalSI = merge(LarvalSI, LarvalSum[,c("id", "TowReplicate", "TowID")], by = "id")
Larval = merge(Larval, LarvalSum[,c("id", "TowReplicate", "TowID")], by = "id")
#options(geodata_default_path = "c:/you/geodata/path")
#Land Data
#can<-getData('GADM', country="CAN", level=1) #getData is discontinued
can<-gadm(country='CAN', level=1, path = "geodata_default_path",version="latest", resolution = 1, regions = c("New Brunswick", "Nova Scotia", "Prince Edward Island", "Newfoundland and Labrador", "Québec"))
#us = getData('GADM', country = "USA", level = 1) # getData is discontinued
us<-gadm(country='USA', level=1, path = "geodata_default_path",version="latest", resolution = 1, regions = c("Maine"))
can1 = rbind(can,us)
NBNS = can1
#NBNS <- can1[can1@data$NAME_1%in%c("New Brunswick","Nova Scotia","Prince Edward Island","Newfoundland and Labrador","Québec", "Maine"),]
NBNS <- as(NBNS, "Spatial") #This causes it to run very slowly - takes about 20 minutes to process.
year= substr(Sys.Date(),1,4)
knitr::opts_knit$set(root.dir = paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/"))
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, fig.align='center')
#Import all packages, CTD data, and land data
#Packages
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Main Data/"))
library(ggplot2)
library(patchwork)
library(scales)
library(cli)
library(lubridate)
library(reprex)
library(tidyverse)
library(geosphere)
library(reshape2)
library(moderndive)
library(skimr)
library(ggridges)
#library(weathercan)
library(GGally)
library(psych)
library(raster)
library(PBSmapping)
#library(rgeos)
library(sf)
library(terra)
library(knitr)
library(kableExtra)
library(grid)
library(gridExtra)
library(cowplot)
library(DT)
library(dygraphs)
library(leaflet)
library(rmapshaper)
library(plotly)
library(mapproj)
library(oce) #new CTD Data package
library(pander)
library(geodata)
library(pacman)
library(rnaturalearth)
library(rnaturalearthdata)
library(raster)
library(devtools)
library(maps)
library(dplyr)
devtools::install_github("ropensci/rnaturalearthhires")
install.packages('GADMTools')
install.packages("Rtools44")
#Tagging Data
Tag = read_csv("TaggingEvents.csv") #Tagging Data
polysT = read_csv("timGrounds.csv") #Coloured ground maps
Tag$Year = as.factor(Tag$Year)
Tag$Vessel = as.factor(Tag$Vessel)
Tag$Survey = as.factor(Tag$Survey)
Tag$Tagger = as.factor(Tag$Tagger)
#CTD Data
SST = read_csv("CTD SST.csv") #SST
polysT = read_csv("timGrounds.csv") #coloured ground maps
CTD = read_csv("CTD Full.csv") #All Data
atDepth = read_csv("CTD 30m.csv") #At 30m Depth > This one contains all Stratified Temp + Salinity data as well
SST$Year <- as.factor(SST$Year)
SST$Month <- as.factor(SST$Month)
atDepth$Year <- as.factor(atDepth$Year)
atDepth$Month <- as.factor(atDepth$Month)
CTD$Year <- as.factor(CTD$Year)
CTD$Month <- as.factor(CTD$Month)
CTD$Survey <- as.factor(CTD$Survey)
CTD <- CTD %>%
mutate(Julian_factor = Julian)
CTD$Julian_factor <- as.factor(CTD$Julian_factor)
#SSB Data
SSB = read_csv("SSB Estimates USING 2024 HSC NUMBERS.csv")
SSB$Year <- as.factor(SSB$Year)
SSB$Survey_Number <- as.factor(SSB$Survey_Number)
SSB$Ground <- as.factor(SSB$Ground)
#LRP Data
LRP2 = read_csv("LRP Data 2024 HSC numbers.csv")
LRP2 = LRP2 %>% rename(ThreeYear = "3yr Avg")
#Fat Data
FatData = read_csv("Total Fat Data.csv")
#Larval Data
#All Adjusted Ages and Dates are originally added in Larval QC script.
#All preservative length adjustments added in in Larval QC script.
# if preservative is formalin, apply L  = 0.984 + 0.993 x X1. (X1 = fixed/preserved length therefore Larval$Lengthmm, L = Live length.)
# if preservation is alcohol apply L = 0.532 + 0.989 x X1
#This is taken from Fox 1996 alcohol vs Formalin paper. They did 5% and 5 minute net capture simulation. They did suggest that this adjustment would be less accurate the longer the tow period.
# These equations are when the maximum shrinkage has occurred.
Larval = read_csv("Full Larval.csv")
Larval$Date <- lubridate::ymd(Larval$Date)
Larval <- dplyr::arrange(Larval, Date)
Larval$Year <- as.factor(Larval$Year)
Larval$category <- as.factor(Larval$category)
Larval$Survey.No <- as.factor(Larval$Survey.No)
Larval$MonthDay <- format(Larval$Date, "%m-%d")
LarvalSI = filter(Larval, Ground == "SI")
LarvalSum = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Larval Data/LarvalSum.csv"))
LarvalSum$Year <- as.factor(LarvalSum$Year)
#Land Data
#can<-getData('GADM', country="CAN", level=1) #getData is discontinued
can<-gadm(country='CAN', level=1, path = "geodata_default_path",version="latest", resolution = 1, regions = c("New Brunswick", "Nova Scotia", "Prince Edward Island", "Newfoundland and Labrador", "Québec"))
#us = getData('GADM', country = "USA", level = 1) # getData is discontinued
us<-gadm(country='USA', level=1, path = "geodata_default_path",version="latest", resolution = 1, regions = c("Maine"))
can1 = rbind(can,us)
NBNS = can1
#NBNS <- can1[can1@data$NAME_1%in%c("New Brunswick","Nova Scotia","Prince Edward Island","Newfoundland and Labrador","Québec", "Maine"),]
NBNS <- as(NBNS, "Spatial") #This causes it to run very slowly - takes about 20 minutes to process.
year= substr(Sys.Date(),1,4)
knitr::opts_knit$set(root.dir = paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/"))
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, fig.align='center')
#Import all packages, CTD data, and land data
#Packages
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Main Data/"))
library(ggplot2)
library(patchwork)
library(scales)
library(cli)
library(lubridate)
library(reprex)
library(tidyverse)
library(geosphere)
library(reshape2)
library(moderndive)
library(skimr)
library(ggridges)
#library(weathercan)
library(GGally)
library(psych)
library(raster)
library(PBSmapping)
#library(rgeos)
library(sf)
library(terra)
library(knitr)
library(kableExtra)
library(grid)
library(gridExtra)
library(cowplot)
library(DT)
library(dygraphs)
library(leaflet)
library(rmapshaper)
library(plotly)
library(mapproj)
library(oce) #new CTD Data package
library(pander)
library(geodata)
library(pacman)
library(rnaturalearth)
library(rnaturalearthdata)
library(raster)
library(devtools)
library(maps)
library(dplyr)
devtools::install_github("ropensci/rnaturalearthhires")
install.packages('GADMTools')
install.packages("Rtools44")
#Tagging Data
Tag = read_csv("TaggingEvents.csv") #Tagging Data
polysT = read_csv("timGrounds.csv") #Coloured ground maps
Tag$Year = as.factor(Tag$Year)
Tag$Vessel = as.factor(Tag$Vessel)
Tag$Survey = as.factor(Tag$Survey)
Tag$Tagger = as.factor(Tag$Tagger)
#CTD Data
SST = read_csv("CTD SST.csv") #SST
polysT = read_csv("timGrounds.csv") #coloured ground maps
CTD = read_csv("CTD Full.csv") #All Data
atDepth = read_csv("CTD 30m.csv") #At 30m Depth > This one contains all Stratified Temp + Salinity data as well
SST$Year <- as.factor(SST$Year)
SST$Month <- as.factor(SST$Month)
atDepth$Year <- as.factor(atDepth$Year)
atDepth$Month <- as.factor(atDepth$Month)
CTD$Year <- as.factor(CTD$Year)
CTD$Month <- as.factor(CTD$Month)
CTD$Survey <- as.factor(CTD$Survey)
CTD <- CTD %>%
mutate(Julian_factor = Julian)
CTD$Julian_factor <- as.factor(CTD$Julian_factor)
#SSB Data
SSB = read_csv("SSB Estimates USING 2024 HSC NUMBERS.csv")
SSB$Year <- as.factor(SSB$Year)
SSB$Survey_Number <- as.factor(SSB$Survey_Number)
SSB$Ground <- as.factor(SSB$Ground)
#LRP Data
LRP2 = read_csv("LRP Data 2024 HSC numbers.csv")
LRP2 = LRP2 %>% rename(ThreeYear = "3yr Avg")
#Fat Data
FatData = read_csv("Total Fat Data.csv")
#Larval Data
#All Adjusted Ages and Dates are originally added in Larval QC script.
#All preservative length adjustments added in in Larval QC script.
# if preservative is formalin, apply L  = 0.984 + 0.993 x X1. (X1 = fixed/preserved length therefore Larval$Lengthmm, L = Live length.)
# if preservation is alcohol apply L = 0.532 + 0.989 x X1
#This is taken from Fox 1996 alcohol vs Formalin paper. They did 5% and 5 minute net capture simulation. They did suggest that this adjustment would be less accurate the longer the tow period.
# These equations are when the maximum shrinkage has occurred.
Larval = read_csv("Full Larval.csv")
Larval$Date <- lubridate::ymd(Larval$Date)
Larval <- dplyr::arrange(Larval, Date)
Larval$Year <- as.factor(Larval$Year)
Larval$category <- as.factor(Larval$category)
Larval$Survey.No <- as.factor(Larval$Survey.No)
Larval$MonthDay <- format(Larval$Date, "%m-%d")
LarvalSI = filter(Larval, Ground == "SI")
LarvalSum = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Larval Data/LarvalSum.csv"))
LarvalSum$Year <- as.factor(LarvalSum$Year)
#Land Data
#can<-getData('GADM', country="CAN", level=1) #getData is discontinued
can<-gadm(country='CAN', level=1, path = "geodata_default_path",version="latest", resolution = 1, regions = c("New Brunswick", "Nova Scotia", "Prince Edward Island", "Newfoundland and Labrador", "Québec"))
#us = getData('GADM', country = "USA", level = 1) # getData is discontinued
us<-gadm(country='USA', level=1, path = "geodata_default_path",version="latest", resolution = 1, regions = c("Maine"))
can1 = rbind(can,us)
NBNS = can1
#NBNS <- can1[can1@data$NAME_1%in%c("New Brunswick","Nova Scotia","Prince Edward Island","Newfoundland and Labrador","Québec", "Maine"),]
NBNS <- as(NBNS, "Spatial") #This causes it to run very slowly - takes about 20 minutes to process.
#Import All Boxes
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Box Coordinates/"))
boxes = read.csv("surveyBoxes.csv")
# Scots Bay plankton and CTD box
SBplankton=boxes[which(boxes$Box == "SBPlanktonBox"), ]
SBCTD=boxes[which(boxes$Box == "SBocean"), ]
# Scots Bay
SUA = read.csv("polygon_SBEastern.csv")
polyEastern = as.PolySet(SUA, projection="LL")
SUA = read.csv("polygon_SBNorthern.csv")
polyNorthern = as.PolySet(SUA, projection="LL")
SUA = read.csv("polygon_SB.csv")
polySB_main = as.PolySet(SUA, projection="LL")
#German Bank CTD box
GBCTD=boxes[which(boxes$Box == "GBocean"), ]
# German Bank
SUA = read.csv("polygon_GB.csv")
polyGB = as.PolySet(SUA, projection="LL")
# Seal Island
SUA = read.csv("polygon_SI.csv")
polySI = as.PolySet(SUA, projection="LL")
LRP2 %>% dplyr::select(Year, Biomass, LRP, ThreeYear) %>%
dygraph(ylab = "Biomass (mt)", xlab = "Year") %>%
dyOptions(drawPoints = TRUE, pointSize = 2) %>%
dyHighlight(highlightCircleSize = 5,
highlightSeriesBackgroundAlpha = 0.8,
hideOnMouseOut = FALSE)
LRP2 %>% dplyr::select(Year, Biomass, LRP, ThreeYear) %>%
dygraph(ylab = "Biomass (mt)", xlab = "Year") %>%
dyOptions(drawPoints = TRUE, pointSize = 2) %>%
axis(1, at = seq(1999, 2024, by = 1), las = 2) %>%
dyHighlight(highlightCircleSize = 5,
highlightSeriesBackgroundAlpha = 0.8,
hideOnMouseOut = FALSE)
LRP2 %>% dplyr::select(Year, Biomass, LRP, ThreeYear) %>%
dygraph(ylab = "Biomass (mt)", xlab = "Year") %>%
dyOptions(drawPoints = TRUE, pointSize = 2) %>%
dyHighlight(highlightCircleSize = 5,
highlightSeriesBackgroundAlpha = 0.8,
hideOnMouseOut = FALSE)
View(LRP2)
#LRP Data
LRP2 = read_csv("LRP Data 2024 HSC numbers.csv")
#LRP Data
LRP2 = read_csv("LRP Data 2024 HSC numbers.csv")
#Tagging Data
Tag = read_csv("TaggingEvents.csv") #Tagging Data
#Packages
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Main Data/"))
#LRP Data
LRP2 = read_csv("LRP Data 2024 HSC numbers.csv")
year= substr(Sys.Date(),1,4)
knitr::opts_knit$set(root.dir = paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/"))
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, fig.align='center')
#Import all packages, CTD data, and land data
local({r <- getOption("repos")
r["CRAN"] <- "https://cran.r-project.org"
options(repos=r)
})
#Packages
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Main Data/"))
library(ggplot2)
library(patchwork)
library(scales)
library(cli)
library(lubridate)
library(reprex)
library(tidyverse)
library(geosphere)
library(reshape2)
library(moderndive)
library(skimr)
library(ggridges)
#library(weathercan)
library(GGally)
library(psych)
library(raster)
library(PBSmapping)
#library(rgeos)
library(sf)
library(terra)
library(knitr)
library(kableExtra)
library(grid)
library(gridExtra)
library(cowplot)
library(DT)
library(dygraphs)
library(leaflet)
library(rmapshaper)
library(plotly)
library(mapproj)
library(oce) #new CTD Data package
library(pander)
library(geodata)
library(pacman)
library(rnaturalearth)
library(rnaturalearthdata)
library(raster)
library(devtools)
library(maps)
library(dplyr)
devtools::install_github("ropensci/rnaturalearthhires")
install.packages('GADMTools')
install.packages("Rtools44")
#Tagging Data
Tag = read_csv("TaggingEvents.csv") #Tagging Data
polysT = read_csv("timGrounds.csv") #Coloured ground maps
Tag$Year = as.factor(Tag$Year)
Tag$Vessel = as.factor(Tag$Vessel)
Tag$Survey = as.factor(Tag$Survey)
Tag$Tagger = as.factor(Tag$Tagger)
#CTD Data
SST = read_csv("CTD SST.csv") #SST
polysT = read_csv("timGrounds.csv") #coloured ground maps
CTD = read_csv("CTD Full.csv") #All Data
atDepth = read_csv("CTD 30m.csv") #At 30m Depth > This one contains all Stratified Temp + Salinity data as well
SST$Year <- as.factor(SST$Year)
SST$Month <- as.factor(SST$Month)
atDepth$Year <- as.factor(atDepth$Year)
atDepth$Month <- as.factor(atDepth$Month)
CTD$Year <- as.factor(CTD$Year)
CTD$Month <- as.factor(CTD$Month)
CTD$Survey <- as.factor(CTD$Survey)
CTD <- CTD %>%
mutate(Julian_factor = Julian)
CTD$Julian_factor <- as.factor(CTD$Julian_factor)
#SSB Data
SSB = read_csv("SSB Estimates USING 2024 HSC NUMBERS.csv")
SSB$Year <- as.factor(SSB$Year)
SSB$Survey_Number <- as.factor(SSB$Survey_Number)
SSB$Ground <- as.factor(SSB$Ground)
#LRP Data
LRP2 = read_csv("LRP Data 2024 HSC numbers.csv")
LRP2 = LRP2 %>% rename(ThreeYear = "3yr Avg")
#Fat Data
FatData = read_csv("Total Fat Data.csv")
#Larval Data
#All Adjusted Ages and Dates are originally added in Larval QC script.
#All preservative length adjustments added in in Larval QC script.
# if preservative is formalin, apply L  = 0.984 + 0.993 x X1. (X1 = fixed/preserved length therefore Larval$Lengthmm, L = Live length.)
# if preservation is alcohol apply L = 0.532 + 0.989 x X1
#This is taken from Fox 1996 alcohol vs Formalin paper. They did 5% and 5 minute net capture simulation. They did suggest that this adjustment would be less accurate the longer the tow period.
# These equations are when the maximum shrinkage has occurred.
Larval = read_csv("Full Larval.csv")
Larval$Date <- lubridate::ymd(Larval$Date)
Larval <- dplyr::arrange(Larval, Date)
Larval$Year <- as.factor(Larval$Year)
Larval$category <- as.factor(Larval$category)
Larval$Survey.No <- as.factor(Larval$Survey.No)
Larval$MonthDay <- format(Larval$Date, "%m-%d")
LarvalSI = filter(Larval, Ground == "SI")
LarvalSum = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Larval Data/LarvalSum.csv"))
LarvalSum$Year <- as.factor(LarvalSum$Year)
#Land Data
#can<-getData('GADM', country="CAN", level=1) #getData is discontinued
can<-gadm(country='CAN', level=1, path = "geodata_default_path",version="latest", resolution = 1, regions = c("New Brunswick", "Nova Scotia", "Prince Edward Island", "Newfoundland and Labrador", "Québec"))
#us = getData('GADM', country = "USA", level = 1) # getData is discontinued
us<-gadm(country='USA', level=1, path = "geodata_default_path",version="latest", resolution = 1, regions = c("Maine"))
can1 = rbind(can,us)
NBNS = can1
#NBNS <- can1[can1@data$NAME_1%in%c("New Brunswick","Nova Scotia","Prince Edward Island","Newfoundland and Labrador","Québec", "Maine"),]
NBNS <- as(NBNS, "Spatial") #This causes it to run very slowly - takes about 20 minutes to process.
#Import All Boxes
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Box Coordinates/"))
boxes = read.csv("surveyBoxes.csv")
# Scots Bay plankton and CTD box
SBplankton=boxes[which(boxes$Box == "SBPlanktonBox"), ]
SBCTD=boxes[which(boxes$Box == "SBocean"), ]
# Scots Bay
SUA = read.csv("polygon_SBEastern.csv")
polyEastern = as.PolySet(SUA, projection="LL")
SUA = read.csv("polygon_SBNorthern.csv")
polyNorthern = as.PolySet(SUA, projection="LL")
SUA = read.csv("polygon_SB.csv")
polySB_main = as.PolySet(SUA, projection="LL")
#German Bank CTD box
GBCTD=boxes[which(boxes$Box == "GBocean"), ]
# German Bank
SUA = read.csv("polygon_GB.csv")
polyGB = as.PolySet(SUA, projection="LL")
# Seal Island
SUA = read.csv("polygon_SI.csv")
polySI = as.PolySet(SUA, projection="LL")
LRP2 %>% dplyr::select(Year, Biomass, LRP, ThreeYear) %>%
dygraph(ylab = "Biomass (mt)", xlab = "Year") %>%
dyOptions(drawPoints = TRUE, pointSize = 2) %>%
dyHighlight(highlightCircleSize = 5,
highlightSeriesBackgroundAlpha = 0.8,
hideOnMouseOut = FALSE)
