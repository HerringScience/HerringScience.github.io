cat("\n")
print(ggplot(data = subset(atDepth1, Year == i), aes(x = Julian, y = StratTemp, colour = Year)) +
geom_point() +
geom_line() +
ylab("Temperature Difference") +
xlab("Julian Day") +
ylim(c(0, 8)) +
ggtitle("German Bank"))
cat("\n")
}
ggplot(data = subset(atDepth, Ground == "German Bank"), aes(x = Julian, y = StratSalt, colour = Year)) +
geom_point() +
ylab("Salinity Difference") +
xlab("Julian Day") +
ylim(c(0, 1.8)) +
ggtitle("German Bank")
ggplot(data = subset(atDepth, Ground == "German Bank"), aes(x=Year, y=StratSalt, group = Year, colour = Year)) +
geom_boxplot() +
stat_summary(fun.y = median, fun.ymax = length,
geom = "text", aes(label = ..ymax..), vjust = -1) +
ylim(NA,1.6) +
labs(x="Year", y = "Salinity Difference (PSS)", title = "Salinity Difference (Stratification) vs. Year")
atDepth1 = atDepth %>%
filter(Ground == "German Bank") %>%
arrange(Survey)
for(i in unique(atDepth1$Year)) {
cat("\n")
cat("######", i, "\n")
cat("\n")
print(ggplot(data = subset(atDepth1, Year == i), aes(x = Julian, y = StratSalt, colour = Year)) +
geom_point() +
geom_line() +
ylab("Salinity Difference") +
xlab("Julian Day") +
ylim(c(0, 1.8)) +
ggtitle("German Bank"))
cat("\n")
}
CP <- as(extent(-65.5, -64.5, 45, 45.5), "SpatialPolygons")
proj4string(CP) <- CRS(proj4string(NBNS))
out <- crop(NBNS, CP, byid=TRUE)
ggplot(data = subset(CTD, Ground == "Scots Bay"), aes(x=Lon, y=Lat)) +
geom_polygon(data=out,aes(x=long, y=lat, group=group)) +
geom_polygon(data=polySB_main,aes(x=X, y=Y, group=PID), colour = "black", fill="white",linetype = 3) +
geom_polygon(data=SBplankton,aes(x=X, y=Y, group=PID), colour = "black", fill="white",linetype = 3) +
geom_polygon(data=SBCTD,aes(x=X, y=Y, group=PID), colour = "black", fill = "white", linetype = 3) +
geom_polygon(data=polyNorthern,aes(x=X, y=Y, group=PID), colour = "black", fill="white",linetype = 3) +
geom_polygon(data=polyEastern,aes(x=X, y=Y, group=PID), colour = "black", fill="white",linetype = 3) +
geom_point(aes(fill = Year), pch=21, size = 2) +
coord_map() +
labs(x=NULL, y=NULL)
CP <- as(extent(-66.5, -65.5, 43, 44), "SpatialPolygons")
proj4string(CP) <- CRS(proj4string(NBNS))
out <- crop(NBNS, CP, byid=TRUE)
ggplot(data = subset(CTD, Ground == "German Bank" & In_Box == "1"), aes(x=Lon, y=Lat)) +
geom_polygon(data=out,aes(x=long, y=lat, group=group)) +
geom_polygon(data=polyGB,aes(x=X, y=Y, group=PID), colour = "black", fill="white",linetype = 3) +
geom_polygon(data=polySI,aes(x=X, y=Y, group=PID), colour = "black", fill="white",linetype = 3) +
geom_polygon(data=GBCTD,aes(x=X, y=Y, group=PID), colour = "black", fill = "white", linetype = 3) +
geom_point(aes(fill = Year), pch=21, size = 2) +
coord_map() +
labs(x=NULL, y=NULL)
#Reset spatial extent back to full view
CP <- as(extent(-69, -63, 42, 45.5), "SpatialPolygons")
proj4string(CP) <- CRS(proj4string(NBNS))
out <- crop(NBNS, CP, byid=TRUE)
ggplot(data = CTD, aes(x=Lon, y=Lat)) +
geom_polygon(data=polysT,aes(x=X, y=Y, group=Box, fill = Box), colour = "black") +
geom_polygon(data=out,aes(x=long, y=lat, group=group),fill='burlywood4',col='black') +
geom_point(pch=21, size = 2, fill = "White")+ ggtitle("CTD Cast Locations") +
labs(x=NULL, y=NULL) +
coord_map() +
theme(panel.background = element_rect(fill = "grey68"))
Larval1 <- subset.data.frame(Larval, Ground == "SB")
Larval1 %>% ggplot(aes(y=LengthAdjustment, x=Survey.No, colour = Year)) +
geom_point(position = "jitter") +
labs(y="Length (mm)", x="Survey Number")
#clear environment first
rm(list=ls())
year= substr(Sys.Date(),1,4)
knitr::opts_knit$set(root.dir = paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/"))
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, fig.align='center')
#Import all packages, CTD data, and land data
#Packages
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Main Data/"))
library(ggplot2)
library(patchwork)
library(scales)
library(cli)
library(lubridate)
library(reprex)
library(tidyverse)
library(geosphere)
library(reshape2)
library(moderndive)
library(skimr)
library(ggridges)
#library(weathercan)
library(GGally)
library(psych)
library(raster)
library(PBSmapping)
#library(rgeos)
library(sf)
library(terra)
library(knitr)
library(kableExtra)
library(grid)
library(gridExtra)
library(cowplot)
library(DT)
library(dygraphs)
library(leaflet)
library(rmapshaper)
library(plotly)
library(mapproj)
library(oce) #new CTD Data package
library(pander)
#Survey Data
surveyData <- read_csv("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Main Data/Survey Data.csv")
#Tagging Data
Tag = read_csv("TaggingEvents.csv") #Tagging Data
polysT = read_csv("timGrounds.csv") #Coloured ground maps
Tag$Year = as.factor(Tag$Year)
Tag$Vessel = as.factor(Tag$Vessel)
Tag$Survey = as.factor(Tag$Survey)
Tag$Tagger = as.factor(Tag$Tagger)
#CTD Data
SST = read_csv("CTD SST.csv") #SST
polysT = read_csv("timGrounds.csv") #coloured ground maps
CTD = read_csv("CTD Full.csv") #All Data
atDepth = read_csv("CTD 30m.csv") #At 30m Depth > This one contains all Stratified Temp + Salinity data as well
SST$Year <- as.factor(SST$Year)
SST$Month <- as.factor(SST$Month)
atDepth$Year <- as.factor(atDepth$Year)
atDepth$Month <- as.factor(atDepth$Month)
CTD$Year <- as.factor(CTD$Year)
CTD$Month <- as.factor(CTD$Month)
CTD$Survey <- as.factor(CTD$Survey)
CTD <- CTD %>%
mutate(Julian_factor = Julian)
CTD$Julian_factor <- as.factor(CTD$Julian_factor)
#SSB Data
SSB = read_csv("SSB Estimates.csv")
SSB$Year <- as.factor(SSB$Year)
SSB$Survey_Number <- as.factor(SSB$Survey_Number)
SSB$Ground <- as.factor(SSB$Ground)
#LRP Data
LRP2 = read_csv("LRP Data.csv")
LRP2 = LRP2 %>% rename(ThreeYear = "3yr Avg")
#Fat Data
FatData = read_csv("Total Fat Data.csv")
#Larval Data
#All Adjusted Ages and Dates are originally added in Larval QC script.
#All preservative length adjustments added in in Larval QC script.
# if preservative is formalin, apply L  = 0.984 + 0.993 x X1. (X1 = fixed/preserved length therefore Larval$Lengthmm, L = Live length.)
# if preservation is alcohol apply L = 0.532 + 0.989 x X1
#This is taken from Fox 1996 alcohol vs Formalin paper. They did 5% and 5 minute net capture simulation. They did suggest that this adjustment would be less accurate the longer the tow period.
# These equations are when the maximum shrinkage has occurred.
#Adjusted Spawn Date to account for incubation period. Using overall 10 days, as per NOAA info that says 7-10 days, and DFO stock assessment 2020 says 10-12 days.
Larval = read_csv("Full Larval.csv")
Larval$Date <- lubridate::ymd(Larval$Date)
Larval <- dplyr::arrange(Larval, Date)
Larval$Year <- as.factor(Larval$Year)
Larval$category <- as.factor(Larval$category)
Larval$Survey.No <- as.factor(Larval$Survey.No)
Larval$MonthDay <- format(Larval$Date, "%m-%d")
Larval$AdjustedJulianSpawnDate <- as.numeric(Larval$AdjustedJulianSpawnDate)
Larval$AdjustedJulianSpawnDate <- as.numeric(Larval$AdjustedJulianSpawnDate)
#Seal Island Larval
LarvalSI = filter(Larval, Ground == "SI")
LarvalSum = read_csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Source Data/Larval Data/LarvalSum.csv"))
LarvalSum = read_csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Source Data/Larval Data/LarvalSum.csv"))
LarvalSum$Year <- as.factor(LarvalSum$Year)
#Land Data
can<-getData('GADM', country="CAN", level=1)
us = getData('GADM', country = "USA", level = 1)
can1 = rbind(can,us)
can1 = rbind(can,us)
NBNS <- can1[can1@data$NAME_1%in%c("New Brunswick","Nova Scotia","Prince Edward Island","Newfoundland and Labrador","QuÃ©bec", "Maine"),]
#Import All Boxes
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Box Coordinates/"))
boxes = read.csv("surveyBoxes.csv")
# Scots Bay plankton and CTD box
SBplankton=boxes[which(boxes$Box == "SBPlanktonBox"), ]
SBCTD=boxes[which(boxes$Box == "SBocean"), ]
# Scots Bay
SUA = read.csv("polygon_SBEastern.csv")
polyEastern = as.PolySet(SUA, projection="LL")
SUA = read.csv("polygon_SBNorthern.csv")
polyNorthern = as.PolySet(SUA, projection="LL")
SUA = read.csv("polygon_SB.csv")
polySB_main = as.PolySet(SUA, projection="LL")
#German Bank CTD box
GBCTD=boxes[which(boxes$Box == "GBocean"), ]
# German Bank
SUA = read.csv("polygon_GB.csv")
polyGB = as.PolySet(SUA, projection="LL")
# Seal Island
SUA = read.csv("polygon_SI.csv")
polySI = as.PolySet(SUA, projection="LL")
Larval1 <- subset.data.frame(Larval, Ground == "SB")
Larval1 %>% ggplot(aes(y=LengthAdjustment, x=Julian, colour = Year)) +
geom_jitter(size = 1.25, width = 3) +
geom_hline(yintercept = 8, linetype = "longdash", size =1, colour = "red")  +
geom_hline(yintercept = 12, linetype = "longdash", size =1, colour = "blue")  +
geom_hline(yintercept = 17, linetype = "longdash", size =1, colour = "forestgreen") +
geom_hline(yintercept = 27, linetype = "longdash", size =1, colour = "grey70") +
labs(y="Length (mm)", x="Julian Date")
#Import all packages, CTD data, and land data
#Packages
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Main Data/"))
library(ggplot2)
library(patchwork)
library(scales)
library(cli)
library(lubridate)
library(reprex)
library(tidyverse)
library(geosphere)
library(reshape2)
library(moderndive)
library(skimr)
library(ggridges)
#library(weathercan)
library(GGally)
library(psych)
library(raster)
library(PBSmapping)
#library(rgeos)
library(sf)
library(terra)
library(knitr)
library(kableExtra)
library(grid)
library(gridExtra)
library(cowplot)
library(DT)
library(dygraphs)
library(leaflet)
library(rmapshaper)
library(plotly)
library(mapproj)
library(oce) #new CTD Data package
library(pander)
#Survey Data
surveyData <- read_csv("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Main Data/Survey Data.csv")
#Tagging Data
Tag = read_csv("TaggingEvents.csv") #Tagging Data
polysT = read_csv("timGrounds.csv") #Coloured ground maps
Tag$Year = as.factor(Tag$Year)
Tag$Vessel = as.factor(Tag$Vessel)
Tag$Survey = as.factor(Tag$Survey)
Tag$Tagger = as.factor(Tag$Tagger)
#CTD Data
SST = read_csv("CTD SST.csv") #SST
polysT = read_csv("timGrounds.csv") #coloured ground maps
CTD = read_csv("CTD Full.csv") #All Data
atDepth = read_csv("CTD 30m.csv") #At 30m Depth > This one contains all Stratified Temp + Salinity data as well
SST$Year <- as.factor(SST$Year)
SST$Month <- as.factor(SST$Month)
atDepth$Year <- as.factor(atDepth$Year)
atDepth$Month <- as.factor(atDepth$Month)
CTD$Year <- as.factor(CTD$Year)
CTD$Month <- as.factor(CTD$Month)
CTD$Survey <- as.factor(CTD$Survey)
CTD <- CTD %>%
mutate(Julian_factor = Julian)
CTD$Julian_factor <- as.factor(CTD$Julian_factor)
#SSB Data
SSB = read_csv("SSB Estimates.csv")
SSB$Year <- as.factor(SSB$Year)
SSB$Survey_Number <- as.factor(SSB$Survey_Number)
SSB$Ground <- as.factor(SSB$Ground)
#LRP Data
LRP2 = read_csv("LRP Data.csv")
LRP2 = LRP2 %>% rename(ThreeYear = "3yr Avg")
#Fat Data
FatData = read_csv("Total Fat Data.csv")
#Larval Data
#All Adjusted Ages and Dates are originally added in Larval QC script.
#All preservative length adjustments added in in Larval QC script.
# if preservative is formalin, apply L  = 0.984 + 0.993 x X1. (X1 = fixed/preserved length therefore Larval$Lengthmm, L = Live length.)
# if preservation is alcohol apply L = 0.532 + 0.989 x X1
#This is taken from Fox 1996 alcohol vs Formalin paper. They did 5% and 5 minute net capture simulation. They did suggest that this adjustment would be less accurate the longer the tow period.
# These equations are when the maximum shrinkage has occurred.
#Adjusted Spawn Date to account for incubation period. Using overall 10 days, as per NOAA info that says 7-10 days, and DFO stock assessment 2020 says 10-12 days.
Larval = read_csv("Full Larval.csv")
Larval$Date <- lubridate::ymd(Larval$Date)
Larval <- dplyr::arrange(Larval, Date)
Larval$Year <- as.factor(Larval$Year)
Larval$category <- as.factor(Larval$category)
Larval$Survey.No <- as.factor(Larval$Survey.No)
Larval$MonthDay <- format(Larval$Date, "%m-%d")
Larval$AdjustedJulianSpawnDate <- as.numeric(Larval$AdjustedJulianSpawnDate)
View(Larval)
Larval$JulianSpawnDate <- as.numeric(Larval$JulianSpawnDate)
TagReturns2024 = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Tag Returns 2023.csv"))
Tags = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Tag Returns/TaggingEvents.csv"))
## Global options
rm(list = ls())
library(cli)
library(lubridate)
library(reprex)
library(tidyverse)
library(geosphere)
library(reshape2)
library(moderndive)
library(skimr)
library(ggridges)
#library(weathercan)
library(GGally)
library(psych)
library(raster)
library(PBSmapping)
#library(rgeos)
library(knitr)
library(kableExtra)
library(grid)
library(gridExtra)
library(cowplot)
library(measurements)
Tags = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Tag Returns/TaggingEvents.csv"))
setwd(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/"))
Tags = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Tag Returns/TaggingEvents.csv"))
Tags = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/TaggingEvents.csv"))
TagReturns2021 = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Tag Returns/Tag Returns 2021.csv"))
TagReturns2021 = subset()
TagReturns2022 = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Tag Returns/Tag Returns 2022.csv"))
TagReturns2023 = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Tag Returns/Tag Returns 2023.csv"))
TagReturns2024 = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Tag Returns/Tag Returns 2023.csv"))
#Load all of Canada data and extract Atlantic provinces
can<-getData('GADM', country="CAN", level=1) # provinces
NBNS <- can[can@data$NAME_1%in%c("New Brunswick","Nova Scotia","Prince Edward Island","Newfoundland and Labrador","Qu?bec"),]
# Proper coordinates for Tagging
CP1 <- as(extent(-69, -62, 42, 46), "SpatialPolygons")
# Proper coordinates for GB plankton tow
CP2 <- as(extent(-67, -65, 43, 43.6), "SpatialPolygons")
# Coordinates for German Bank and Spec
CP3 <- as(extent(-67, -65, 43, 44), "SpatialPolygons")
# Scots
CP4 <- as(extent(-66, -63, 44, 46), "SpatialPolygons")
# Scotia Shelf
CP5 <- as(extent(-65, -60, 43, 46), "SpatialPolygons")
# Grand Manan Area
CP6 <- as(extent(-68, -66, 44, 45), "SpatialPolygons")
#Reduce Province data down to only the above extents/limits
proj4string(CP1) <- CRS(proj4string(NBNS))
All <- gIntersection(NBNS, CP1, byid=TRUE)
#Load boxes
#Import All Boxes
setwd(paste0("C:/Users/", Sys.info()[7], "/Documents/GitHub/HerringScience.github.io/Box Coordinates/"))
points = read.csv("Points.csv")
boxes = read.csv("timGrounds.csv")
#Tim Grounds
SUA = read.csv("timGrounds.csv")
# Scots Bay plankton and CTD box
SBplankton=boxes[which(boxes$Box == "SBPlanktonBox"), ]
SBCTD=boxes[which(boxes$Box == "SBocean"), ]
# Scots Bay
SUA = read.csv("polygon_SBEastern.csv")
polyEastern = as.PolySet(SUA, projection="LL")
SUA = read.csv("polygon_SBNorthern.csv")
polyNorthern = as.PolySet(SUA, projection="LL")
SUA = read.csv("polygon_SB.csv")
polySB_main = as.PolySet(SUA, projection="LL")
#German Bank CTD box
GBCTD=boxes[which(boxes$Box == "GBocean"), ]
# German Bank
SUA = read.csv("polygon_GB.csv")
polyGB = as.PolySet(SUA, projection="LL")
# Seal Island
SUA = read.csv("polygon_SI.csv")
polySI = as.PolySet(SUA, projection="LL")
#Add tagging data
setwd(paste0("C:/Users/", Sys.info()[7], "/Documents/GitHub/HerringScience.github.io/Source Data/"))
tags = read.csv("TaggingEvents.csv")
#All Data at once
ggplot(boxes,aes(x=X, y=Y)) +
geom_polygon(aes(colour = Box),fill= NA,lwd=1) +
geom_polygon(data=All,aes(x=long, y=lat, group=group)) +
geom_point(data=Tag1, aes(x=Lon, y=Lat, colour = Date), size=3) +
coord_map() +
labs(x=NULL, y=NULL)
CP6 <- as(extent(-68, -66, 44, 45), "SpatialPolygons")
proj4string(CP6) <- CRS(proj4string(NBNS))
GM <- gIntersection(NBNS, CP6, byid=TRUE)
GM <- crop(NBNS, CP6, byid=TRUE)
All <- crop(NBNS, CP1, byid=TRUE)
## Global options
rm(list = ls())
library(cli)
library(lubridate)
library(reprex)
library(tidyverse)
library(geosphere)
library(reshape2)
library(moderndive)
library(skimr)
library(ggridges)
#library(weathercan)
library(GGally)
library(psych)
library(raster)
library(PBSmapping)
#library(rgeos)
library(knitr)
library(kableExtra)
library(grid)
library(gridExtra)
library(cowplot)
library(measurements)
setwd(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/"))
#All Tags deployed
Tags = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/TaggingEvents.csv"))
#Tag Returns from during the AFF 44 funding
TagReturns2021 = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Tag Returns/Tag Returns 2021.csv"))
TagReturns2021 = subset()
## Global options
rm(list = ls())
library(cli)
library(lubridate)
library(reprex)
library(tidyverse)
library(geosphere)
library(reshape2)
library(moderndive)
library(skimr)
library(ggridges)
#library(weathercan)
library(GGally)
library(psych)
library(raster)
library(PBSmapping)
#library(rgeos)
library(knitr)
library(kableExtra)
library(grid)
library(gridExtra)
library(cowplot)
library(measurements)
setwd(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/"))
Tags = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/TaggingEvents.csv"))
TagReturns2021 = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Tag Returns/Tag Returns 2021.csv"))
TagReturns2021 = subset()
TagReturns2021 = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Tag Returns/Tag Returns 2021.csv"))
TagReturns2022 = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Tag Returns/Tag Returns 2022.csv"))
TagReturns2023 = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Tag Returns/Tag Returns 2023.csv"))
TagReturns2024 = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Tag Returns/Tag Returns 2023.csv"))
#Load all of Canada data and extract Atlantic provinces
can<-getData('GADM', country="CAN", level=1) # provinces
NBNS <- can[can@data$NAME_1%in%c("New Brunswick","Nova Scotia","Prince Edward Island","Newfoundland and Labrador","Qu?bec"),]
# Proper coordinates for Tagging
CP1 <- as(extent(-69, -62, 42, 46), "SpatialPolygons")
# Proper coordinates for GB plankton tow
CP2 <- as(extent(-67, -65, 43, 43.6), "SpatialPolygons")
# Coordinates for German Bank and Spec
CP3 <- as(extent(-67, -65, 43, 44), "SpatialPolygons")
# Scots
CP4 <- as(extent(-66, -63, 44, 46), "SpatialPolygons")
# Scotia Shelf
CP5 <- as(extent(-65, -60, 43, 46), "SpatialPolygons")
# Grand Manan Area
CP6 <- as(extent(-68, -66, 44, 45), "SpatialPolygons")
#Reduce Province data down to only the above extents/limits
proj4string(CP1) <- CRS(proj4string(NBNS))
All <- crop(NBNS, CP1, byid=TRUE)
#Load boxes
#Import All Boxes
setwd(paste0("C:/Users/", Sys.info()[7], "/Documents/GitHub/HerringScience.github.io/Box Coordinates/"))
points = read.csv("Points.csv")
boxes = read.csv("timGrounds.csv")
#Tim Grounds
SUA = read.csv("timGrounds.csv")
# Scots Bay plankton and CTD box
SBplankton=boxes[which(boxes$Box == "SBPlanktonBox"), ]
SBCTD=boxes[which(boxes$Box == "SBocean"), ]
# Scots Bay
SUA = read.csv("polygon_SBEastern.csv")
polyEastern = as.PolySet(SUA, projection="LL")
SUA = read.csv("polygon_SBNorthern.csv")
polyNorthern = as.PolySet(SUA, projection="LL")
SUA = read.csv("polygon_SB.csv")
polySB_main = as.PolySet(SUA, projection="LL")
#German Bank CTD box
GBCTD=boxes[which(boxes$Box == "GBocean"), ]
# German Bank
SUA = read.csv("polygon_GB.csv")
polyGB = as.PolySet(SUA, projection="LL")
# Seal Island
SUA = read.csv("polygon_SI.csv")
polySI = as.PolySet(SUA, projection="LL")
#Add tagging data
setwd(paste0("C:/Users/", Sys.info()[7], "/Documents/GitHub/HerringScience.github.io/Source Data/"))
tags = read.csv("TaggingEvents.csv")
#All Data at once
ggplot(boxes,aes(x=X, y=Y)) +
geom_polygon(aes(colour = Box),fill= NA,lwd=1) +
geom_polygon(data=All,aes(x=long, y=lat, group=group)) +
geom_point(data=Tag1, aes(x=Lon, y=Lat, colour = Date), size=3) +
coord_map() +
labs(x=NULL, y=NULL)
#All Data at once
ggplot(boxes,aes(x=X, y=Y)) +
geom_polygon(aes(colour = Box),fill= NA,lwd=1) +
geom_polygon(data=All,aes(x=long, y=lat, group=group)) +
geom_point(data=TagReturns2024, aes(x=Lon, y=Lat, colour = Date), size=3) +
coord_map() +
labs(x=NULL, y=NULL)
View(tags)
View(TagReturns2024)
TagReturns2024 = read_csv(paste0("C:/Users/herri/Documents/GitHub/HerringScience.github.io/Source Data/Tag Returns/Tag Returns 2024.csv"))
