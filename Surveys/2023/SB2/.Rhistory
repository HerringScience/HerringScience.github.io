#Results
resultsa = biomassCalc(x = GB, areaKm = GB1)
resultsb = biomassCalc(x = SI, areaKm = GB2)
resultsc = biomassCalc(x = trans2, areaKm = GB3)
tableA = resultTableA(x = GB)
tableB = resultTableB(x = GB)
tableC = resultTableC(x = resultsa)
tableD = resultTableA(x = SI)
tableE = resultTableB(x = SI)
tableF = resultTableC(x = resultsb)
tableG = resultTableA(x = trans2)
tableH = resultTableB(x = trans2)
tableI = resultTableC(x = resultsc)
tableC$Layer = "German Bank"
tableF$Layer = "Seal Island"
tableI$Layer = "School Survey"
A = rbind(tableA,tableD, tableG)
B = rbind(tableB,tableE, tableH)
C = rbind(tableC,tableF, tableI)
write.table(A, file= "tableA.csv", sep = ",", quote=FALSE, row.names=FALSE, col.names=TRUE)
write.table(B, file= "tableB.csv", sep = ",", quote=FALSE, row.names=FALSE, col.names=TRUE)
write.table(C, file= "tableC.csv", sep = ",", quote=FALSE, row.names=FALSE, col.names=TRUE)}
###Turnover Calc###
#SB and GB turnover calculation
if(surv == "GB"){
y_intercept = GB_y
x_Var_1 = GB_x_var
daysturnover = GB_days
Bio = C %>% filter(Layer == "German Bank")
}
if(surv == "SB"){
y_intercept =  SB_y
x_Var_1 = SB_x_var
daysturnover = SB_days
Bio = C
}
resultsa$Date <-
as.Date(substr(resultsa$Date_Time_S, 0, 10))
Date <- resultsa$Date
Survey <- 1:length(resultsa$Date)
Biomass <- resultsa$trans_biomass
TurnBio = turnoverBio(y_intercept, x_Var_1, daysturnover, Date, Survey, Biomass)
View(resultsa)
# remove everything in the workspace
rm(list = ls())
# IMPORTANT : SET GROUND, YEAR, AND SURVEY # HERE
surv="SB"
surv2="Scots Bay"
year="2023"
surv.no="2"
adhoc = "FALSE" #true or false if an adhoc survey was completed (and "adhoc.csv" exists)
#Set vessels for SB only
ids = c("C1", "FM", "LJ", "LM", "MS", "SL") #only main box vessels
NorthVessel = "BP" #set NA if none
EastVessel = "TM" #set NA if none
#Area and TS values
SB1= 664 #SB main area
SB2= 87 #SB north area
SB3= 127 #SB east area
TS1 = -35.5 #TS38
GB1 = 805 #GB main area
GB2 = 267 #Seal Island area
GB3 = NA #Ad-hoc school survey area
#turnover calculation regression values
GB_y = 0.199392662629964
GB_x_var = 0.528381832773883
GB_days = 31
SB_y = 0.364102758434224
SB_x_var = 0.436969270679439
SB_days = 15
library(cli)
library(lubridate)
library(reprex)
library(tidyverse)
library(geosphere)
library(reshape2)
library(moderndive)
library(skimr)
library(ggridges)
library(weathercan)
library(GGally)
library(psych)
library(raster)
library(PBSmapping)
library(rgeos)
library(knitr)
library(kableExtra)
library(grid)
library(gridExtra)
library(cowplot)
##Tagging Data
#Data import and filtering
Tag <- read_csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Source Data/TaggingEvents.csv"))
Tag$Date = ymd(Tag$Date)
Tag <- Tag %>% mutate(Julian = yday(Date)) %>% mutate(Year = as.numeric(substr(Date, 1, 4))) %>% dplyr::select(-Tag_Annual)
#Add tags per year per tagger
Tag_Annual = Tag %>%
group_by(Tagger) %>%
mutate(count = n_distinct(Year)) %>%
summarize(n=n(), count2 = mean(count)) %>%
mutate(Tag_Annual = n/count2) %>%
dplyr::select(-n, -count2)
Tag = left_join(Tag, Tag_Annual, by = "Tagger")
#Adding Ground
Tag <- Tag %>%
mutate(Ground = ifelse(between(Lat, 45.02, 45.4) & between(Lon, -65.5, -64.5), "Scots Bay",
ifelse(between(Lat, 43.15, 43.7) & between(Lon, -66.75, -66.05), "German Bank", 'Other')))
#Change any 'Sealife' to 'Sealife II', and other corrections
Tag$Vessel = as.factor(Tag$Vessel)
summary(Tag$Vessel) #spot any issues
Tag$Vessel[which(Tag$Vessel=="Sealife")] <- "Sealife II"
Tag$Vessel[which(Tag$Vessel=="Lady Meliss")] <- "Lady Melissa"
Tag$Vessel[which(Tag$Vessel=="Lady Janice II")] <- "Lady Janice"
summary(Tag$Vessel) #double check
Tag %>% write_csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Main Data/TaggingEvents.csv"))
##ECHOVIEW DATA##
#Land Data
can<-getData('GADM', download = FALSE, country="CAN", level=1, path = "C:/Users/herri/Documents/GitHub/HerringScience.github.io")
us = getData('GADM', download = FALSE, country = "USA", level = 1, path = "C:/Users/herri/Documents/GitHub/HerringScience.github.io")
can1 = rbind(can,us)
NBNS <- can1[can1@data$NAME_1%in%c("New Brunswick","Nova Scotia","Prince Edward Island","Newfoundland and Labrador","Québec", "Maine"),]
# Proper coordinates for German Bank
GBMap <- as(extent(-66.5, -65.5, 43, 44), "SpatialPolygons")
proj4string(GBMap) <- CRS(proj4string(NBNS))
GBout <- gIntersection(NBNS, GBMap, byid=TRUE)
# Proper coordinates for Scots Bay
SBMap <- as(extent(-65.5, -64.5, 45, 45.5), "SpatialPolygons")
proj4string(SBMap) <- CRS(proj4string(NBNS))
SBout <- gIntersection(NBNS, SBMap, byid=TRUE)
#Import All Boxes
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Box Coordinates/"))
boxes = read.csv("surveyBoxes.csv")
SBplankton=boxes[which(boxes$Box == "SBPlanktonBox"), ]
SBCTD=boxes[which(boxes$Box == "SBocean"), ]
SUA = read.csv("polygon_SBEastern.csv")
polyEastern = as.PolySet(SUA, projection="LL")
SUA = read.csv("polygon_SBNorthern.csv")
polyNorthern = as.PolySet(SUA, projection="LL")
SUA = read.csv("polygon_SB.csv")
polySB_main = as.PolySet(SUA, projection="LL")
GBCTD=boxes[which(boxes$Box == "GBocean"), ]
SUA = read.csv("polygon_GB.csv")
polyGB = as.PolySet(SUA, projection="LL")
SUA = read.csv("polygon_SI.csv")
polySI = as.PolySet(SUA, projection="LL")
#Load functions
pathnames <- list.files(pattern="[.]R$", path=paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Source Data/Functions"), full.names=TRUE)
sapply(pathnames, FUN=source)
#Echoview Data
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", surv, surv.no))
Map = list.files(path=paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", surv, surv.no), pattern = "Map") %>%
map_df(~read_csv(.))
Region = list.files(path=paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", surv, surv.no), pattern = "Region") %>%
map_df(~read_csv(.))
if(surv == "SB"){
out = SBout
map = mapDat(x = Map)
x = Region
trans = transects(x= Region, TS38 = TS1, TS50 = NA)
x = surveyTrack3(x=trans, polyNameA  = polySB_main, polyNameB  = polyNorthern,  polyNameC  = polyEastern,  title = name)
northern = trans[which((trans$Vessel == NorthVessel)), ]
eastern = trans[which((trans$Vessel == EastVessel)), ]
main = trans[which((trans$Vessel %in% ids)), ]
ggplot(map, aes(x=Xend, y=Yend)) + geom_point(aes(colour = Vessel, size = PRC_ABC)) + labs(x=NULL, y=NULL)
# Results
resultsa = biomassCalc(x = main, areaKm = SB1)
resultsb = biomassCalc(x = northern, areaKm = SB2)
resultsc = biomassCalc(x = eastern, areaKm = SB3)
tableA = resultTableA(x = main)
tableB = resultTableB(x = main)
tableC = resultTableC(x = resultsa)
tableD = resultTableA(x = northern)
tableE = resultTableB(x = northern)
tableF = resultTableC(x = resultsb)
tableG = resultTableA(x = eastern)
tableH = resultTableB(x = eastern)
tableI = resultTableC(x = resultsc)
tableC$Layer = "Main Box"
tableF$Layer = "Northern Box"
tableI$Layer = "Eastern Box"
A = rbind(tableA,tableD, tableG)
B = rbind(tableB,tableE, tableH)
C = rbind(tableC,tableF, tableI)
write.table(A, file= "tableA.csv", sep = ",", quote=FALSE, row.names=FALSE, col.names=TRUE)
write.table(B, file= "tableB.csv", sep = ",", quote=FALSE, row.names=FALSE, col.names=TRUE)
write.table(C, file= "tableC.csv", sep = ",", quote=FALSE, row.names=FALSE, col.names=TRUE)
}
if(surv=="GB"){
out=GBMap
map = mapDat(x = Map)
x = Region
trans = transects(x= Region, TS38 = TS1 , TS50 = NA)
ids = c("T01", "T02", "T03")
trans1 = trans[which((trans$Transect_No %in% ids)), ]
ids = c("T04", "T05", "T06", "T07")
trans2 = trans[which((trans$Transect_No %in% ids)), ]
x = surveyTrack2(x=trans1, polyNameA  = polyGB, polyNameB  = polySI, title = name )
if(adhoc=="TRUE"){SUA = list.files(path=paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", surv, surv.no), pattern = "adhoc") %>%
map_df(~read_csv(.))
polyAD = as.PolySet(SUA, projection="LL")
x = surveyTrack2(x=trans2, polyNameA  = polyGB, polyNameB  = polyAD, title = name )
ggplot(trans2, aes(x=X, y=Y)) + geom_polygon(data=polyAD,aes(x=X, y=Y, group=PID), fill = "white", colour = "black")  + geom_segment(aes(x = X, y = Y, xend = Xend, yend = Yend, colour = Vessel), size = 1)  + labs(x=NULL, y=NULL) + coord_map()
}
ids = c("T01", "T02", "T03")
map1 = map[which((map$Transect_No %in% ids)), ]
ggplot(map1, aes(x=Xend, y=Yend)) + geom_point(aes(colour = Vessel, size = PRC_ABC)) + labs(x=NULL, y=NULL)
SI = trans[which(trans$Transect_No == "T03"), ]
ids = c("T01", "T02")
GB = trans[which((trans$Transect_No %in% ids)), ]
#Results
resultsa = biomassCalc(x = GB, areaKm = GB1)
resultsb = biomassCalc(x = SI, areaKm = GB2)
resultsc = biomassCalc(x = trans2, areaKm = GB3)
tableA = resultTableA(x = GB)
tableB = resultTableB(x = GB)
tableC = resultTableC(x = resultsa)
tableD = resultTableA(x = SI)
tableE = resultTableB(x = SI)
tableF = resultTableC(x = resultsb)
tableG = resultTableA(x = trans2)
tableH = resultTableB(x = trans2)
tableI = resultTableC(x = resultsc)
tableC$Layer = "German Bank"
tableF$Layer = "Seal Island"
tableI$Layer = "School Survey"
A = rbind(tableA,tableD, tableG)
B = rbind(tableB,tableE, tableH)
C = rbind(tableC,tableF, tableI)
write.table(A, file= "tableA.csv", sep = ",", quote=FALSE, row.names=FALSE, col.names=TRUE)
write.table(B, file= "tableB.csv", sep = ",", quote=FALSE, row.names=FALSE, col.names=TRUE)
write.table(C, file= "tableC.csv", sep = ",", quote=FALSE, row.names=FALSE, col.names=TRUE)}
###Turnover Calc###
#SB and GB turnover calculation
if(surv == "GB"){
y_intercept = GB_y
x_Var_1 = GB_x_var
daysturnover = GB_days
Bio = C %>% filter(Layer == "German Bank")
}
if(surv == "SB"){
y_intercept =  SB_y
x_Var_1 = SB_x_var
daysturnover = SB_days
Bio = C
}
resultsa$Date <-
as.Date(substr(resultsa$Date_Time_S, 0, 10))
Date <- resultsa$Date
Survey <- 1:length(resultsa$Date)
BioA = resultsa$trans_biomass
BioB = resultsb$trans_biomass
BioC = resultsc$trans_biomass
Biomass1 = full_join(BioA, BioB)
BioA = resultsa$trans_biomass
BioB = resultsb$trans_biomass
BioC = resultsc$trans_biomass
Biomass = sum(BioA, BioB, BioC)
TurnBio = turnoverBio(y_intercept, x_Var_1, daysturnover, Date, Survey, Biomass)
if(surv == "SB"){
y_intercept =  SB_y
x_Var_1 = SB_x_var
daysturnover = SB_days
}
resultsa$Date <-
as.Date(substr(resultsa$Date_Time_S, 0, 10))
Date <- resultsa$Date
# remove everything in the workspace
rm(list = ls())
# IMPORTANT : SET GROUND, YEAR, AND SURVEY # HERE
surv="SB"
surv2="Scots Bay"
year="2023"
surv.no="2"
adhoc = "FALSE" #true or false if an adhoc survey was completed (and "adhoc.csv" exists)
#Set vessels for SB only
ids = c("C1", "FM", "LJ", "LM", "MS", "SL") #only main box vessels
NorthVessel = "BP" #set NA if none
EastVessel = "TM" #set NA if none
#Area and TS values
SB1= 664 #SB main area
SB2= 87 #SB north area
SB3= 127 #SB east area
TS1 = -35.5 #TS38
GB1 = 805 #GB main area
GB2 = 267 #Seal Island area
GB3 = NA #Ad-hoc school survey area
#turnover calculation regression values
GB_y = 0.199392662629964
GB_x_var = 0.528381832773883
GB_days = 31
SB_y = 0.364102758434224
SB_x_var = 0.436969270679439
SB_days = 15
library(cli)
library(lubridate)
library(reprex)
library(tidyverse)
library(geosphere)
library(reshape2)
library(moderndive)
library(skimr)
library(ggridges)
library(weathercan)
library(GGally)
library(psych)
library(raster)
library(PBSmapping)
library(rgeos)
library(knitr)
library(kableExtra)
library(grid)
library(gridExtra)
library(cowplot)
##Tagging Data
#Data import and filtering
Tag <- read_csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Source Data/TaggingEvents.csv"))
Tag$Date = ymd(Tag$Date)
Tag <- Tag %>% mutate(Julian = yday(Date)) %>% mutate(Year = as.numeric(substr(Date, 1, 4))) %>% dplyr::select(-Tag_Annual)
#Add tags per year per tagger
Tag_Annual = Tag %>%
group_by(Tagger) %>%
mutate(count = n_distinct(Year)) %>%
summarize(n=n(), count2 = mean(count)) %>%
mutate(Tag_Annual = n/count2) %>%
dplyr::select(-n, -count2)
Tag = left_join(Tag, Tag_Annual, by = "Tagger")
#Adding Ground
Tag <- Tag %>%
mutate(Ground = ifelse(between(Lat, 45.02, 45.4) & between(Lon, -65.5, -64.5), "Scots Bay",
ifelse(between(Lat, 43.15, 43.7) & between(Lon, -66.75, -66.05), "German Bank", 'Other')))
#Change any 'Sealife' to 'Sealife II', and other corrections
Tag$Vessel = as.factor(Tag$Vessel)
summary(Tag$Vessel) #spot any issues
Tag$Vessel[which(Tag$Vessel=="Sealife")] <- "Sealife II"
Tag$Vessel[which(Tag$Vessel=="Lady Meliss")] <- "Lady Melissa"
Tag$Vessel[which(Tag$Vessel=="Lady Janice II")] <- "Lady Janice"
summary(Tag$Vessel) #double check
Tag %>% write_csv(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Main Data/TaggingEvents.csv"))
##ECHOVIEW DATA##
#Land Data
can<-getData('GADM', download = FALSE, country="CAN", level=1, path = "C:/Users/herri/Documents/GitHub/HerringScience.github.io")
us = getData('GADM', download = FALSE, country = "USA", level = 1, path = "C:/Users/herri/Documents/GitHub/HerringScience.github.io")
can1 = rbind(can,us)
NBNS <- can1[can1@data$NAME_1%in%c("New Brunswick","Nova Scotia","Prince Edward Island","Newfoundland and Labrador","Québec", "Maine"),]
# Proper coordinates for German Bank
GBMap <- as(extent(-66.5, -65.5, 43, 44), "SpatialPolygons")
proj4string(GBMap) <- CRS(proj4string(NBNS))
GBout <- gIntersection(NBNS, GBMap, byid=TRUE)
# Proper coordinates for Scots Bay
SBMap <- as(extent(-65.5, -64.5, 45, 45.5), "SpatialPolygons")
proj4string(SBMap) <- CRS(proj4string(NBNS))
SBout <- gIntersection(NBNS, SBMap, byid=TRUE)
#Import All Boxes
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Box Coordinates/"))
boxes = read.csv("surveyBoxes.csv")
SBplankton=boxes[which(boxes$Box == "SBPlanktonBox"), ]
SBCTD=boxes[which(boxes$Box == "SBocean"), ]
SUA = read.csv("polygon_SBEastern.csv")
polyEastern = as.PolySet(SUA, projection="LL")
SUA = read.csv("polygon_SBNorthern.csv")
polyNorthern = as.PolySet(SUA, projection="LL")
SUA = read.csv("polygon_SB.csv")
polySB_main = as.PolySet(SUA, projection="LL")
GBCTD=boxes[which(boxes$Box == "GBocean"), ]
SUA = read.csv("polygon_GB.csv")
polyGB = as.PolySet(SUA, projection="LL")
SUA = read.csv("polygon_SI.csv")
polySI = as.PolySet(SUA, projection="LL")
#Load functions
pathnames <- list.files(pattern="[.]R$", path=paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Source Data/Functions"), full.names=TRUE)
sapply(pathnames, FUN=source)
#Echoview Data
setwd(paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", surv, surv.no))
Map = list.files(path=paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", surv, surv.no), pattern = "Map") %>%
map_df(~read_csv(.))
Region = list.files(path=paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", surv, surv.no), pattern = "Region") %>%
map_df(~read_csv(.))
if(surv == "SB"){
out = SBout
map = mapDat(x = Map)
x = Region
trans = transects(x= Region, TS38 = TS1, TS50 = NA)
x = surveyTrack3(x=trans, polyNameA  = polySB_main, polyNameB  = polyNorthern,  polyNameC  = polyEastern,  title = name)
northern = trans[which((trans$Vessel == NorthVessel)), ]
eastern = trans[which((trans$Vessel == EastVessel)), ]
main = trans[which((trans$Vessel %in% ids)), ]
ggplot(map, aes(x=Xend, y=Yend)) + geom_point(aes(colour = Vessel, size = PRC_ABC)) + labs(x=NULL, y=NULL)
# Results
resultsa = biomassCalc(x = main, areaKm = SB1)
resultsb = biomassCalc(x = northern, areaKm = SB2)
resultsc = biomassCalc(x = eastern, areaKm = SB3)
tableA = resultTableA(x = main)
tableB = resultTableB(x = main)
tableC = resultTableC(x = resultsa)
tableD = resultTableA(x = northern)
tableE = resultTableB(x = northern)
tableF = resultTableC(x = resultsb)
tableG = resultTableA(x = eastern)
tableH = resultTableB(x = eastern)
tableI = resultTableC(x = resultsc)
tableC$Layer = "Main Box"
tableF$Layer = "Northern Box"
tableI$Layer = "Eastern Box"
A = rbind(tableA,tableD, tableG)
B = rbind(tableB,tableE, tableH)
C = rbind(tableC,tableF, tableI)
write.table(A, file= "tableA.csv", sep = ",", quote=FALSE, row.names=FALSE, col.names=TRUE)
write.table(B, file= "tableB.csv", sep = ",", quote=FALSE, row.names=FALSE, col.names=TRUE)
write.table(C, file= "tableC.csv", sep = ",", quote=FALSE, row.names=FALSE, col.names=TRUE)
}
if(surv=="GB"){
out=GBMap
map = mapDat(x = Map)
x = Region
trans = transects(x= Region, TS38 = TS1 , TS50 = NA)
ids = c("T01", "T02", "T03")
trans1 = trans[which((trans$Transect_No %in% ids)), ]
ids = c("T04", "T05", "T06", "T07")
trans2 = trans[which((trans$Transect_No %in% ids)), ]
x = surveyTrack2(x=trans1, polyNameA  = polyGB, polyNameB  = polySI, title = name )
if(adhoc=="TRUE"){SUA = list.files(path=paste0("C:/Users/", Sys.info()[7],"/Documents/GitHub/HerringScience.github.io/Surveys/", year, "/", surv, surv.no), pattern = "adhoc") %>%
map_df(~read_csv(.))
polyAD = as.PolySet(SUA, projection="LL")
x = surveyTrack2(x=trans2, polyNameA  = polyGB, polyNameB  = polyAD, title = name )
ggplot(trans2, aes(x=X, y=Y)) + geom_polygon(data=polyAD,aes(x=X, y=Y, group=PID), fill = "white", colour = "black")  + geom_segment(aes(x = X, y = Y, xend = Xend, yend = Yend, colour = Vessel), size = 1)  + labs(x=NULL, y=NULL) + coord_map()
}
ids = c("T01", "T02", "T03")
map1 = map[which((map$Transect_No %in% ids)), ]
ggplot(map1, aes(x=Xend, y=Yend)) + geom_point(aes(colour = Vessel, size = PRC_ABC)) + labs(x=NULL, y=NULL)
SI = trans[which(trans$Transect_No == "T03"), ]
ids = c("T01", "T02")
GB = trans[which((trans$Transect_No %in% ids)), ]
#Results
resultsa = biomassCalc(x = GB, areaKm = GB1)
resultsb = biomassCalc(x = SI, areaKm = GB2)
resultsc = biomassCalc(x = trans2, areaKm = GB3)
tableA = resultTableA(x = GB)
tableB = resultTableB(x = GB)
tableC = resultTableC(x = resultsa)
tableD = resultTableA(x = SI)
tableE = resultTableB(x = SI)
tableF = resultTableC(x = resultsb)
tableG = resultTableA(x = trans2)
tableH = resultTableB(x = trans2)
tableI = resultTableC(x = resultsc)
tableC$Layer = "German Bank"
tableF$Layer = "Seal Island"
tableI$Layer = "School Survey"
A = rbind(tableA,tableD, tableG)
B = rbind(tableB,tableE, tableH)
C = rbind(tableC,tableF, tableI)
write.table(A, file= "tableA.csv", sep = ",", quote=FALSE, row.names=FALSE, col.names=TRUE)
write.table(B, file= "tableB.csv", sep = ",", quote=FALSE, row.names=FALSE, col.names=TRUE)
write.table(C, file= "tableC.csv", sep = ",", quote=FALSE, row.names=FALSE, col.names=TRUE)}
###Turnover Calc###
#SB and GB turnover calculation
if(surv == "GB"){
y_intercept = GB_y
x_Var_1 = GB_x_var
daysturnover = GB_days
Bio = C %>% filter(Layer == "German Bank")
}
if(surv == "SB"){
y_intercept =  SB_y
x_Var_1 = SB_x_var
daysturnover = SB_days
}
resultsa$Date <-
as.Date(substr(resultsa$Date_Time_S, 0, 10))
Date <- resultsa$Date
Survey <- 1:length(resultsa$Date)
BioA = resultsa$trans_biomass
BioB = resultsb$trans_biomass
BioC = resultsc$trans_biomass
Biomass = sum(BioA, BioB, BioC)
TurnBio = turnoverBio(y_intercept, x_Var_1, daysturnover, Date, Survey, Biomass)
install.packages(c("adehabitatHR", "adehabitatLT", "adehabitatMA", "bit", "blob", "bookdown", "broom", "bslib", "cachem", "callr", "checkmate", "classInt", "cli", "colorspace", "commonmark", "cpp11", "crayon", "curl", "data.table", "dbplyr", "deldir", "digest", "dismo", "dplyr", "DT", "dtplyr", "e1071", "evaluate", "fansi", "fastmap", "forcats", "Formula", "fs", "gargle", "geometries", "geosphere", "ggmap", "ggplot2", "ggrepel", "googledrive", "googlesheets4", "gstat", "gtable", "haven", "highr", "Hmisc", "hms", "htmltools", "htmlwidgets", "httr", "infer", "interp", "isoband", "janitor", "jpeg", "jsonlite", "knitr", "later", "lifecycle", "lubridate", "lwgeom", "mapdata", "mapproj", "maps", "maptools", "markdown", "mnormt", "modelr", "moderndive", "openssl", "PBSmapping", "pillar", "plotly", "plyr", "png", "processx", "ps", "psych", "purrr", "raster", "Rcpp", "RcppArmadillo", "RcppEigen", "readr", "readxl", "repr", "rgdal", "rgeos", "rlang", "rmarkdown", "s2", "sass", "sf", "skimr", "sp", "spacetime", "stars", "stringi", "stringr", "svglite", "sys", "terra", "tibble", "tidyr", "tidyselect", "tidyverse", "tinytex", "tzdb", "units", "utf8", "vctrs", "viridis", "viridisLite", "vroom", "wk", "xfun", "XML", "xml2", "xts", "yaml", "zoo"))
install.packages(c("adehabitatHR", "adehabitatLT", "adehabitatMA", "bit", "blob", "bookdown", "broom", "bslib", "cachem", "callr", "checkmate", "classInt", "cli", "colorspace", "commonmark", "cpp11", "crayon", "curl", "data.table", "dbplyr", "deldir", "digest", "dismo", "dplyr", "DT", "dtplyr", "e1071", "evaluate", "fansi", "fastmap", "forcats", "Formula", "fs", "gargle", "geometries", "geosphere", "ggmap", "ggplot2", "ggrepel", "googledrive", "googlesheets4", "gstat", "gtable", "haven", "highr", "Hmisc", "hms", "htmltools", "htmlwidgets", "httr", "infer", "interp", "isoband", "janitor", "jpeg", "jsonlite", "knitr", "later", "lifecycle", "lubridate", "lwgeom", "mapdata", "mapproj", "maps", "maptools", "markdown", "mnormt", "modelr", "moderndive", "openssl", "PBSmapping", "pillar", "plotly", "plyr", "png", "processx", "ps", "psych", "purrr", "raster", "Rcpp", "RcppArmadillo", "RcppEigen", "readr", "readxl", "repr", "rgdal", "rgeos", "rlang", "rmarkdown", "s2", "sass", "sf", "skimr", "sp", "spacetime", "stars", "stringi", "stringr", "svglite", "sys", "terra", "tibble", "tidyr", "tidyselect", "tidyverse", "tinytex", "tzdb", "units", "utf8", "vctrs", "viridis", "viridisLite", "vroom", "wk", "xfun", "XML", "xml2", "xts", "yaml", "zoo"))
install.packages(c("adehabitatHR", "adehabitatLT", "adehabitatMA", "bit", "blob", "bookdown", "broom", "bslib", "cachem", "callr", "checkmate", "classInt", "cli", "colorspace", "commonmark", "cpp11", "crayon", "curl", "data.table", "dbplyr", "deldir", "digest", "dismo", "dplyr", "DT", "dtplyr", "e1071", "evaluate", "fansi", "fastmap", "forcats", "Formula", "fs", "gargle", "geometries", "geosphere", "ggmap", "ggplot2", "ggrepel", "googledrive", "googlesheets4", "gstat", "gtable", "haven", "highr", "Hmisc", "hms", "htmltools", "htmlwidgets", "httr", "infer", "interp", "isoband", "janitor", "jpeg", "jsonlite", "knitr", "later", "lifecycle", "lubridate", "lwgeom", "mapdata", "mapproj", "maps", "maptools", "markdown", "mnormt", "modelr", "moderndive", "openssl", "PBSmapping", "pillar", "plotly", "plyr", "png", "processx", "ps", "psych", "purrr", "raster", "Rcpp", "RcppArmadillo", "RcppEigen", "readr", "readxl", "repr", "rgdal", "rgeos", "rlang", "rmarkdown", "s2", "sass", "sf", "skimr", "sp", "spacetime", "stars", "stringi", "stringr", "svglite", "sys", "terra", "tibble", "tidyr", "tidyselect", "tidyverse", "tinytex", "tzdb", "units", "utf8", "vctrs", "viridis", "viridisLite", "vroom", "wk", "xfun", "XML", "xml2", "xts", "yaml", "zoo"))
install.packages(c("adehabitatHR", "adehabitatLT", "adehabitatMA", "bit", "blob", "bookdown", "broom", "bslib", "cachem", "callr", "checkmate", "classInt", "cli", "colorspace", "commonmark", "cpp11", "crayon", "curl", "data.table", "dbplyr", "deldir", "digest", "dismo", "dplyr", "DT", "dtplyr", "e1071", "evaluate", "fansi", "fastmap", "forcats", "Formula", "fs", "gargle", "geometries", "geosphere", "ggmap", "ggplot2", "ggrepel", "googledrive", "googlesheets4", "gstat", "gtable", "haven", "highr", "Hmisc", "hms", "htmltools", "htmlwidgets", "httr", "infer", "interp", "isoband", "janitor", "jpeg", "jsonlite", "knitr", "later", "lifecycle", "lubridate", "lwgeom", "mapdata", "mapproj", "maps", "maptools", "markdown", "mnormt", "modelr", "moderndive", "openssl", "PBSmapping", "pillar", "plotly", "plyr", "png", "processx", "ps", "psych", "purrr", "raster", "Rcpp", "RcppArmadillo", "RcppEigen", "readr", "readxl", "repr", "rgdal", "rgeos", "rlang", "rmarkdown", "s2", "sass", "sf", "skimr", "sp", "spacetime", "stars", "stringi", "stringr", "svglite", "sys", "terra", "tibble", "tidyr", "tidyselect", "tidyverse", "tinytex", "tzdb", "units", "utf8", "vctrs", "viridis", "viridisLite", "vroom", "wk", "xfun", "XML", "xml2", "xts", "yaml", "zoo"))
install.packages(c("adehabitatHR", "adehabitatLT", "adehabitatMA", "bit", "blob", "bookdown", "broom", "bslib", "cachem", "callr", "checkmate", "classInt", "cli", "colorspace", "commonmark", "cpp11", "crayon", "curl", "data.table", "dbplyr", "deldir", "digest", "dismo", "dplyr", "DT", "dtplyr", "e1071", "evaluate", "fansi", "fastmap", "forcats", "Formula", "fs", "gargle", "geometries", "geosphere", "ggmap", "ggplot2", "ggrepel", "googledrive", "googlesheets4", "gstat", "gtable", "haven", "highr", "Hmisc", "hms", "htmltools", "htmlwidgets", "httr", "infer", "interp", "isoband", "janitor", "jpeg", "jsonlite", "knitr", "later", "lifecycle", "lubridate", "lwgeom", "mapdata", "mapproj", "maps", "maptools", "markdown", "mnormt", "modelr", "moderndive", "openssl", "PBSmapping", "pillar", "plotly", "plyr", "png", "processx", "ps", "psych", "purrr", "raster", "Rcpp", "RcppArmadillo", "RcppEigen", "readr", "readxl", "repr", "rgdal", "rgeos", "rlang", "rmarkdown", "s2", "sass", "sf", "skimr", "sp", "spacetime", "stars", "stringi", "stringr", "svglite", "sys", "terra", "tibble", "tidyr", "tidyselect", "tidyverse", "tinytex", "tzdb", "units", "utf8", "vctrs", "viridis", "viridisLite", "vroom", "wk", "xfun", "XML", "xml2", "xts", "yaml", "zoo"))
# remove everything in the workspace
rm(list = ls())
# IMPORTANT : SET GROUND, YEAR, AND SURVEY # HERE
surv="SB"
surv2="Scots Bay"
year="2023"
surv.no="2"
adhoc = "FALSE" #true or false if an adhoc survey was completed (and "adhoc.csv" exists)
#Set vessels for SB only
ids = c("C1", "FM", "LJ", "LM", "MS", "SL") #only main box vessels
NorthVessel = "BP" #set NA if none
EastVessel = "TM" #set NA if none
#Area and TS values
SB1= 664 #SB main area
SB2= 87 #SB north area
SB3= 127 #SB east area
TS1 = -35.5 #TS38
GB1 = 805 #GB main area
GB2 = 267 #Seal Island area
GB3 = NA #Ad-hoc school survey area
#turnover calculation regression values
GB_y = 0.199392662629964
GB_x_var = 0.528381832773883
GB_days = 31
SB_y = 0.364102758434224
SB_x_var = 0.436969270679439
SB_days = 29
library(cli)
library(lubridate)
library(reprex)
library(tidyverse)
